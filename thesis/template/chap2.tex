\chapter{Layout Languages as Sugared Attribute Grammars}
\section{Motivation and Approach}

We start by examining challenges for building layout languages and our high-level solution of automation through attribute grammars.  Throughout this and the remaining chapters, we focus on the design and implementation of one simple layout widget. We will show how our support of it generalizes to common layout languages and, more generally, computations over trees.

\subsection{Important properties for layout languages and others}
Layout languages are some of the most common -- for one gauge, there are over 634 million websites live in 2012, with 51 million added that year~\footnote{http://news.netcraft.com/archives/2012/12/04/december-2012-web-server-survey.html}. Beyond the CSS and HTML languages used for webpage layout, designers also use \LaTeX~[[CITE]] for document layout, D3~[[CITE]] for data visualization, Swing~[[Swing]] for GUI layout, and even specialize within these domains such as by using markdown for text. 


Popular layout languages foster designer productivity by providing abstractions that are rich and numerous.
The alternative is analogous to asking a programmer to write in a low-level language such as assembly: designers should not manually specify, for each element, the position on a canvas and the style. Instead, layout languages resemble constraint systems where designers  declare high-level properties. For example, the high-level program \code{hello world} states that the words \code{hello} and \code{world} should be rendered, and word \code{world} should follow line-wrapping rules for its positioning after \code{hello}. Layout languages may provide quite complicated constraints -- for example, most document layout languages resort to defining their line wrapping rule  in a flexible low-level language. Likewise, they may provide many featuress, such as in the 250+ pages of rules for the CSS language. Adding to the sophistication, many languages support designers adding their own constraints, such as through macros in \LaTeX,  percentage constraints in CSS, and arbitrary functions in Adobe Flex~[[CITE]]. 

The richness of popular layout languages comes at the cost of of complicating their design and implementation:

\begin{itemize}
\item \textbf{Safe semantics.} Does every input layout have exactly one unique rendering? Are the constraints restricted enough such that an efficient implementation is feasible for low-power devices, big data sets, and fast animation? When a feature is added, does it conflict with anything of the above properties? We want an automated way to verify such properties.
\item \textbf{Safe implementation.} As a layout language grows in popularity, it grows in features. Likewise, developers will port it to many platforms and optimize it, and in cases such as CSS, reimplement it from scratch. Does the implementation conform to the intended semantics? Conformance bugs for CSS plague developers~[[CITE]], and failures to match {\LaTeX}'s semantics have killed multiple attempts to modernize the implementation. We want an automated way to ensure that the implementation matches the specification.
\item \textbf{Advanced implementation.} Layout languages tend to add feature as they evolve. However, the implementation of each feature also has demands that increase with time: improved speed and memory footprint, better debugging support, etc. Browser layout engines for CSS are currently over 100,000 lines of optimized C++ code, and most rich layout languages thus far have resisted parallelization. We want automation techniques to lower the implementation burden and more aggressively target those goals.
\end{itemize}


\begin{figure}
\centering
\includegraphics[trim=0 0 0 0,clip,width=1.0\columnwidth]{chapter2/architecture}
\caption{\textbf{Layout engine architecture.} }
\label{fig:architecture}
\end{figure}

Our idea is to declaratively specify layout languages and automatically compile them into an efficient implementation. At runtime, an instance of layout will be processed through the previously generated layout engine (Figure~\ref{fig:architecture}). The compiler is responsible for checking the semantics of the layout features and, by construction, provides a correct implementation. Furthermore, instead of manually optimizing the code for every individual feature, language designers instead write generic compiler optimizations. As a similar implementation benefit, we automatically target multiple platforms for the same layout language, such as scripting languages in order to use their debuggers, and multicore and GPU languages to gain magnitudes of speedups.

We show that the attribute grammar formalism supports specification of layout languages. It is unclear how to encode complicated layout language features with the traditional formalism, so we support a rich form of attribute grammars and reduce reasoning about them to handling a more traditional formalism (reducer in Figure~\ref{fig:architecture}). The remainder of this chapter introduces the high-level attribute grammar formalism, how to specify layout languages using it, and an intuition for the reduction into a lower-level formalism.


\newsavebox{\agdef}
\begin{lrbox}{\agdef}% Store first listing
\begin{minipage}{1\columnwidth}
\setlength{\grammarparsep}{0.15cm}   % vertical distance between production rules
\setlength{\grammarindent}{1cm}
\renewcommand{\litleft}{\bfseries}
\renewcommand{\ulitleft}{\bfseries}
\renewcommand{\superscript}[1]{\ensuremath{^{\textrm{#1}}}}
\renewcommand{\subscript}[1]{\ensuremath{_{\textrm{\uppercase{#1}}}}}
\renewcommand{\syntleft}{\normalfont\itshape}
\renewcommand{\syntright}{}
%\newcommand{\deriv}{~::=~}
\renewcommand{\deriv}{~ $\rightarrow$ ~}
\begin{grammar}
<AG> \deriv{} (<Prod> "\{" <Stmnt>? "\}")*

<Prod> \deriv{} <V> $\rightarrow$ <V>*

<Stmnt> \deriv{} <Attrib> "=" <id>(<Attrib>*) ~  | ~ <Attrib> "=" <n> ~ | ~ <Stmnt> ; <Stmnt> 

<Attrib> \deriv{} <id>.<id>
\end{grammar}
\end{minipage}
\end{lrbox}



\newsavebox{\hboxtreetext}
\begin{lrbox}{\hboxtreetext}% Store first listing
\begin{lstlisting}[language=C++,morekeywords={spawn,join,reverse,parallel_for}]
<S>
  <HBox name=child>
    <HBox name=left>
      <HBox name=left w=20 h=5/>
      <HBox name=right w=15 h=5/>
    </HBox>
    <HBox name=right w=15 h=5/>
  </HBox>
</S>
\end{lstlisting}
\end{lrbox}


\begin{figure}
\subfloat[\textbf{Input tree.} Only some of the x, y, w, and h attributes are specified.]{\label{fig:hbox:input}
\begin{minipage}{1\columnwidth}\centering
\includegraphics[trim=0 0 0 0,clip,width=0.6\columnwidth]{chapter2/output}
\end{minipage}}\\
\subfloat[\textbf{Textual encoding of input tree.}]{\label{fig:hbox:texttree}
\begin{minipage}{1\columnwidth}\centering
\usebox{\hboxtreetext}
\end{minipage}
}\\
\subfloat[\textbf{Attribute grammar for a language of horizontal boxes.}]{\label{fig:hbox:grammar}
\begin{minipage}{1\columnwidth}
\begin{grammar}
<S> \deriv{} \emph{HBOX} \\ 
  \{ HBOX.x = 0; HBOX.y = 0 \}

<HBOX> $\rightarrow$ $\epsilon$  \\
\{ HBOX.w = input$_w$(); HBOX.h = input$_h$() \} 

<HBOX$_0$> $\rightarrow$ \emph{HBOX$_1$} \emph{HBOX$_2$} \\
\{ HBOX$_1$.x = HBOX$_0$.x; \\
$~~~$ HBOX$_2$.x = HBOX$_0$.x + HBOX$_1$.w; \\
$~~~$ HBOX$_1$.y = HBOX$_0$.y; \\
$~~~$ HBOX$_2$.y = HBOX$_0$.y; \\
$~~~$ HBOX$_0$.h = max(HBOX$_1$.h, HBOX$_2$.h); \\
$~~~$ HBOX$_0$.w = HBOX$_1$.w + HBOX$_2$.w \} 
\end{grammar}
\end{minipage}
}\\
\subfloat[\textbf{Language of attribute grammars.}]{\label{fig:ag}
\usebox{\agdef}
}
\caption{For a language of horizontal boxes: (a) input tree to solve and (b) attribute grammar specifying the layout language. Specification language of attribute grammars shown in (c).%and (c) dynamic data dependencies.
}
\label{fig:hbox}
\end{figure}


\section{Background: Layout with Classical Attribute Grammar}

This section describes specifying a simple layout language as an attribute grammar and two classical implementation strategies. We reuse the example throughout our work to explore various concepts.



\subsection{Attribute Grammars}

Consider solving the tree of horizontal boxes shown in Figure~\frefb{fig:hbox}{fig:hbox:input}. As input, a webpage author provides a tree with constraints (Figure~\frefb{fig:hbox}{fig:hbox:text tree}). Only some node attribute values are provided: in this case, only the widths and heights of leaf nodes. The meaning of a horizontal layout is that, as is visualized, the boxes will be placed side-by-side. The layout engine must solve for all remaining x, y, width, and height attributes. 

We declaratively specify the layout language of horizontal boxes, \hlang{},  as shown in Figure~\frefb{fig:hbox}{fig:hbox:grammar}, with an attribute grammar~\cite{oag,Meyerovich:2010,htmlag}. First, the specification defines the set of well-formed input trees as the derivations of a context-free grammar. We use the standard notation~[[CITE]]. In this case, a document is an unbalanced binary tree of arbitrary depth where the root node has label \texttt{S} and intermediate nodes have label \texttt{HBOX}. Second, the specification defines semantic functions that relate attributes associated with each node. For example, the width of an intermediate horizontal node is the sum of its children widths. Likewise, the width of a leaf node is provided by the user, which is encoded by the nullary function call $input_w()$:


\begin{grammar}
<HBOX> $\rightarrow$ $\epsilon$ \{ HBOX.w = $input_w$(); $\ldots$ \} ~~~~~~~~~~~~~~~~~~~~~~~ /* leaf */

<HBOX$_0$> $\rightarrow$ \emph{HBOX$_1$} \emph{HBOX$_2$} ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ /* binary node */\\
\{ $\ldots$ HBOX$_0$.w = HBOX$_1$.w + HBOX$_2$.w \} 
\end{grammar}


The specification intentionally does not define the evaluation order. For example, the specification does not state whether to compute a node's width before its height. Likewise, our optimized approach will compute the attributes as a sequence of tree traversals, but the specification does not state what those traversals are. Leaving the evaluation order unspecified provides freedom for our compilers to pick an efficient parallel order. Irrespective of whatever evaluation order is ultimately used to solve for the attribute values, the statements define constraints that must hold over the computed result. Attribute grammars can therefore be thought of as a single assignment language where attributes are dataflow variables~[[CITE]].


The language of attribute grammars is defined in Figure~\frefb{fig:hbox}{fig:ag}. In addition the defining the context free grammar, it supports single-assignment constraints over attributes of nodes in a production. Our example uses the following encoding. Semantic functions are pure and left uninterpreted, so, for example, we encode the addition of widths as ``\mbox{HBOX$_0$.w = f(HBOX$_1$.w, HBOX$_2$.w)}''. Our program analysis techniques do not need to know the contents of the function, just that the output of a call depends purely on the inputs.  For the same reason, we encode constant values as nullary function calls. 

To specify grammars more complicated than \hlang{}, we describe linguistic extensions for richer functional specifications (Section~\ref{sec:desugaring}) and, to control the evaluation order, behavioral specification (Chapters~\ref{chap:3} and \ref{chap:4}).

\begin{figure}
\subfloat[Initial dependencies.]{\label{fig:deps:full}
\begin{minipage}{0.5\columnwidth}\centering
\includegraphics[trim=0 0 0 0,clip,width=1.0\columnwidth]{chapter2/deps}
\end{minipage}}
\subfloat[After first round of evaluation.]{\label{fig:deps:step}
\begin{minipage}{0.5\columnwidth}\centering
\includegraphics[trim=0 0 0 0,clip,width=1.0\columnwidth]{chapter2/depsstep}
\end{minipage}}
\caption{\textbf{Dynamic data dependencies and evaluation}. Shown for constraint tree  in Figure~ZZZ~(a). Circles denote attributes, with black circles denote attributes with resolved dependencies such as \sched{input()}s. Thin lines show data dependencies and thick lines show production derivations. Second chart shows the dependency graph resulting from evaluating all source nodes and marking them as resolved.}
\label{fig:deps}
\end{figure}


\subsection{Dynamic data dependencies and dynamic evaluation}
A simple and classic evaluation strategy is to \emph{dynamically} compute over a tree. The evaluator dynamically follows the dynamic data dependencies between instances of attributes. The dynamic evaluation strategy is too slow for our use cases, but it introduces the key concepts of dynamic data dependencies, the dynamic semantics of attributes grammars, and the corresponding dynamic interpreter.

An instance of a document corresponds to the dependency graph shown in Figure~\frefb{fig:reps}{fig:deps:full}. Each attribute of a tree node is either a source, meaning its value can be computed based on other known values, or it cannot be evaluated until other attribute values are known. It is a dynamic dependency graph in that each data dependency in the static code may be instantiated as multiple data dependencies given a tree at runtime. 

The dynamic data dependency graph leads to a simple semantics for the result of evaluation. The graph corresponds to a system of equations where edges link instance variables. For example, static code \code{HBOX$_2$.x = HBOX$_0$.x + HBOX$_1$.w} instantiates twice for the Figure~\frefb{fig:deps}{fig:reps:full}: once for each $x$ attribute with an incoming elbow connector. The value of both $x$s are constrained by distinct instances of the above constraint. If the dependency graph is a directed acyclic graph and each attribute appears on the lefthand side of exactly one equality statement (\emph{dataflow variables}), there is exactly one solution to the system of equations.

A simple procedure solves an instance of a system of equations: topological traversal. The algorithm is as follows:
\begin{figure}
\begin{lstlisting}[mathescape,language=C++,morekeywords={for,in,where,input,output,repeat,until,return}]
input: $G = (V,E)$
output: $Map$
$Map \leftarrow \emptyset$
$E' \leftarrow E$
$V' \leftarrow V$
for $a \in V' \texttt{where} \not\exists (n,a) \in E'$:
  $Map \leftarrow Map \cup \{a \rightarrow \texttt{eval}(a)\}$
  $V' \leftarrow V' - a$
  $E' \leftarrow E' \ (\{a\} \times V)$
repeat until $E' = \emptyset$
return $Map$
\end{lstlisting}
\caption{\textbf{Dynamic attribute grammar evaluator.} It selects attributes in a safe order by dynamically removing dependency edges as they are resolved. }
\label{fig:dyneval}
\end{figure}
The algorithm literately finds an attribute whose dependencies have all been previously resolved, evaluates the attribute, and repeats. If the input graph is a directed acyclic graph, this procedure is guaranteed to terminate. The insight is that a directed acyclic graph has at least one fringe node, the loop removes them, and removing these nodes yields a smaller directed acylic graph.

The dynamic evaluation strategy provides a small explanation for the natural semantics, but it leaves several challenges. First, runtime manipulation of a dynamic dependency graph introduces high overheads because every dynamic dependency edge must be manipulated. Second, it is unsafe. For example, a cycle in the dependency graph causes the above evaluation strategy to get stuck, so dynamic evaluators must introduce runtime cycle check. Designers can build layout widgets that, depending on how they are invoked, fail to display!

%\subsection{Static data dependencies and static evaluators}




\section{Desugaring Loops and Other Modern Constructs}
\label{sec:desugaring}

The attribute grammar formalism was invented for describing semantics~[[CITE]] and before many modern constructs became mainstream: we had to design extensions for improved expressiveness and maintainability. Our extensions exploit concepts from structured, object-oriented, and functional programming. Other language designers have build such extensions as well~[[CITE]]: our challenge was to make expressive extensions that facilitate effective parallelization and do not overly complicate language and tool implementation. This section documents the language features and how they simplify implementation, and leaves performance optimization to the next chapter.

Our key insight is that pre- and post-processing supports desugaring a feature-rich attribute grammar into the canonical attribute grammar notation. Tools then operate at the most appropriate stage, such as our scheduler on the small, canonical attribute grammar representation. Likewise, our code generators take a generated schedule and relate it back to a representation from early in the preprocessing stage. Many of the below features are built as explicit compiler stages, but over time, we found that declarative tree rewriting systems such as ANTLR and OMeta support automating individual stages.



\newsavebox{\ifacegrammar}
\begin{lrbox}{\ifacegrammar}% Store first listing
\begin{lstlisting}[language=C++,morekeywords={interface,class,children}]
interface BoxI { }
class HBoxLeaf : BoxI { }
class HBoxBinary : BoxI { 
  children {
    left: BoxI;
    right: BoxI;
  }
}
class VBoxLeaf : BoxI { }
class VBoxBinary : BoxI { 
  children {
    left: Box;
    right: Box;
  }
}
\end{lstlisting}
\end{lrbox}




\begin{figure}
\subfloat[\textbf{Canonical attribute grammar.}]{\label{fig:iface:problem}
\begin{minipage}{1\columnwidth}
\begin{grammar}
<S> \deriv{} \emph{HBOX}  $|$  \emph{VBOX}

<HBOX> \deriv{} $\epsilon$  

<HBOX$_0$> \deriv{} \emph{HBOX$_1$} \emph{HBOX$_2$} 

<HBOX$_0$> \deriv{} \emph{VBOX$_1$} \emph{HBOX$_2$} 

<HBOX$_0$> \deriv{} \emph{HBOX$_1$} \emph{VBOX$_2$} 

<HBOX$_0$> \deriv{} \emph{VBOX$_1$} \emph{VBOX$_2$} 

<VBOX> \deriv{} $\epsilon$  

<VBOX$_0$> \deriv{} \emph{HBOX$_1$} \emph{HBOX$_2$} 

<VBOX$_0$> \deriv{} \emph{VBOX$_1$} \emph{HBOX$_2$} 

<VBOX$_0$> \deriv{} \emph{HBOX$_1$} \emph{VBOX$_2$} 

<VBOX$_0$> \deriv{} \emph{VBOX$_1$} \emph{VBOX$_2$} 

\end{grammar}
\end{minipage}
}\\
\subfloat[\textbf{Interface sugar.}]{\label{fig:iface:clean}
\usebox{\ifacegrammar}
}\\
\subfloat[\textbf{Interface encoding.}]{\label{fig:iface:rewrite}
\begin{minipage}{1\columnwidth}
\begin{grammar}
<S> \deriv{} \emph{BOX}

<BOX> \deriv{} \emph{HBOX} $|$ \emph{VBOX}

<HBOX> \deriv{} $\epsilon$  

<HBOX$_0$> \deriv{} \emph{BOX$_1$} \emph{BOX$_2$} 

<VBOX> \deriv{} $\epsilon$  

<VBOX$_0$> \deriv{} \emph{BOX$_1$} \emph{BOX$_2$} 

\end{grammar}
\end{minipage}
}
\caption{\textbf{Interfaces for tree grammars}. Subfigures show manually encoding multiple production right-hand sides, an encoding that uses a \code{Box} non-terminal for indirection, and the high-level encoding using interfaces and classes.}
\label{fig:iface}
\end{figure}


\begin{figure}
\begin{lstlisting}[language=C++,morekeywords={spawn,join,reverse,parallel_for}]
{"class": "HBox",
 "children": {
   "left": {
     "class": "HBox",
     "children": {
       "left":  {"class": "HBox", "w": 20, "h": 5},
       "right": {"class": "HBox", "w": 15, "h": 5}}},
   "right": {
     {"class": "HBox", "w": 15, "h": 5}}}}
\end{lstlisting}
\caption{\textbf{Input tree as graph with labeled nodes and edges}. Specified in the JSON notation.}
\label{fig:hboxjson}
\end{figure}

\subsection{Interfaces for Encoding Tree Grammars}
Attribute grammars are an extension to the tree grammar formalism for defining input trees, so improving the abstraction capabilities of tree grammars also aids the ability to structure attribute grammars. In particular, we found the need to support  abstracting over similar types of non-terminals. Our solution is to provide a notion of classes and interfaces. Our core extension is macro-expressible with attribute grammars and therefore reduces implementation requirements, though it is still important enough that it merits deeper compiler support. 


Consider the code duplication performed when extending \hlang with vertical boxes. The children of a \code{HBox} could be a horizontal box or a vertical box, and the same for the children of a vertical box. Figure~\ref{fig:face:problem} shows that the 3 productions of \hlang grew to be 11. The example highlights that canonical attribute grammars cannot abstract over node types. Adding a new box type requires modifying all previous box classes, and in the presence multiple children, extension suffers exponential costs. 

To abstract over node types, we introduce the notion of classes and interfaces (Figure~\ref{fig:iface:clean}). Classes are similar to the productions of an attribute grammar: the class name specifies the production's lefthand side non-terminal and the children block specifies the production's righthand side. Unlike attribute grammars, an interface name is used for the righthand side rather than the class name. \code{HBox} and \code{VBox} implement interface \code{BoxI}, so any class specified to have a \code{BoxI} child can have a \code{HBox} or \code{VBox} child within the concrete tree. 


Classes and interfaces are formally equivalent to tree grammars in the sense of a 1-to-1 correspondence between trees described by both. First, a tree grammar can be expressed with classes and interfaces by treating all productions with the same lefthand-side non-terminal as different classes belonging to the same interface. In the other direction, each interface can be expressed as a production that derives the classes, and the classes expand into productions. Figures~\ref{fig:iface:clean} and \ref{fig:iface:rewrite} demonstrate the correspondence for \hlang. The induced implementation requirements are therefore slight in the sense that the construct is sugar for a pattern in the canonical attribute grammars. 

We depart from the correspondence for the encoding of trees in two ways. First, we represent input as a tree with labeled nodes and edges. Node labels denote the class and edge labels specify child bindings. Figure~\ref{fig:hboxjson} uses the JSON format common to dynamic languages for an instance of a tree in \hlang. By naming children, such as \code{left} and \code{right}, we eliminate sensitivity to their order within a code block. With order sensitivity, adding a middle child \code{center} would needlessly require refactoring references to the repositioned element \code{right}. Likewise, reordering children in the input data does not require refactoring the attribute grammar.

Our second departure from the canonical attribute grammar encoding optimizes the data representation by eliding intermediate interface nodes. The reduction to attribute grammars suggests adding a new non-terminal for each interface, but doing so in the data representation doubles the number of nodes in the concrete tree. Making the interface pattern a language construct with compiler support eliminates associated costs, such as cutting file size for runtime parsing of big data visualizations.

\begin{figure}
\begin{lstlisting}[language=C++,morekeywords={interface,class,var,input,int,float}]
interface BoxI {
  var x : float;
}
class HBoxLeaf : BoxI {
  attributes {
    var y : int;
    input w : ? int;
    input h : int = 10;
  }
}


\end{lstlisting}
\caption{\textbf{Input tree as graph with labeled nodes and edges}. Specified in the JSON notation.}
\label{fig:hboxjson}
\end{figure}


\subsection{Interfaces for attributes and information hiding.}
Our system provides lightweight specification annotations for different types of attributes, and coupled with the interface construct, it supports defining relationships between attributes across different classes.

Each static attribute is annotated with its assignment type and its embedded value type:
\begin{itemize}
\item \textbf{Assignment types.}
The assignment type denotes whether the input tree defines the value, such as in \code{input w}, or whether the attribute grammar defines it, as in \code{var x}. Assignments to an input type are illegal, and multiple assignments to a variable type are also illegal. 

If an input tree fails to provide an input attribute, a runtime error will be thrown. To still provide an interpretation of such trees, input attributes  support the annotation ''?'',  which enables pattern matching through functions \code{maybeReady :: -> boolean} and \code{maybeValue :: -> 'a}.  Alternatively, for the common scenario of using a fixed default value, a default value can instead be defined as in \code{input h : int = 10}. If the input tree does not provide the value, the default value will be automatically substituted.

Canonical attribute grammars can encode input attributes in two ways. First, semantic functions with no parameters encode the lack of dependencies. Second, for finite domains, the set of tree grammar productions can expand to include attribute nodes. The second encoding more faithfully describes our approach because, like our system, it feeds into an automatic tree parser generator. For each tree node, our generated parser scans for the expected set of input attributes.

\item \textbf{Value types.} 
The system also supports type annotations used for embeddings. Generated code typically compiles as part of a project in a more static language, such as C++, which require a static type discipline. The annotations can be user-defined, such as OpenGL's \emph{vertex buffer object} \code{VBO}, which is not defined within our system.

Our analyzer ignores the value type annotations such as \code{x : float} and \code{y : int} while the low-level code generator passes along the decorations \code{float} and \code{int}.  The embedded design simplifies implementation because value type checking is performed by the host language's compiler. 
\end{itemize}

In practice, we  use attribute definitions in interfaces for information hiding across classes and lightweight specification of relationships between similar classes. An attribute declared inside of a class is \emph{local} to constraints in the class: only the class's constraints can read or write to the attribute. Conversely, declaring a \emph{var} inside of an interface hints that it is meant to be reused by outside classes, such as part of a tree traversal.

\begin{figure}
\begin{lstlisting}[language=C++,morekeywords={trait,class,attributes,actions}]
trait Rectangle {
  attributes { render : int; }
  actions { render := paintRect(x,y,w,h, "black"); }
}
class HBox(Rectangle) : BoxI { ... }
\end{lstlisting}
\caption{\textbf{Trait construct}. Adds shared rendering code to the HBox class.}
\label{fig:trait}
\end{figure}

\subsection{Traits: Reusing Cross-cutting Code}
As with many object systems, we support a trait construct for cross-cutting code that should be shared across classes. It statically expands like a macro, and therefore provides no formal expressive power. For example, Figure~\ref{fig:trait} defines how to render a rectangle given several attributes, and then adds that functionality to class \code{HBox}. If the language was extended with class \code{VBox}, the class definition of \code{VBox} could also use trait \code{Rectangle}.






\begin{figure}
\begin{lstlisting}[language=C++,morekeywords={spawn,join,reverse,parallel_for}]
interface BoxI { }
class HBoxLeaf : BoxI { }
class HBoxBinary : BoxI { 
  children {
    left: BoxI;
    right: BoxI;
  }
}
class VBoxLeaf : BoxI { }
class VBoxBinary : BoxI { 
  children {
    left: Box;
    right: Box;
  }
}
\end{lstlisting}
\caption{\textbf{Input tree as graph with labeled nodes and edges}. Specified in the JSON notation.}
\label{fig:hboxjson}
\end{figure}

\subsection{Loops}
We extend our language with declarative loops over the attributes of multiple nodes. They are an expressive extension over the uniform recurrence relations of [[CITE]].




\subsection{Embedded Domain Specific Language: Functional Rendering}



\section{Evaluation: Mechanized Layout Features}





\subsection{Rendering: Immediate Mode and Beyond}
\subsection{Non-euclidean: Sunburst Diagram}
\subsection{Charts: Line graphs}
\subsection{Animation and Interaction: Treemap}
\subsection{Flow-based: CSS Box Model}
\subsection{Grid-based: HTML Tables}

\section{Related Work}
\begin{itemize}
\item loose formalisms: browser impl (C++), d3 (JavaScript), latex formulas (ML)
\item restricted formalisms: cassowary and hp, UREs
\item AGs: html tables
\end{itemize}



