\chapter{Layout Languages as Sugared Attribute Grammars}
\section{Motivation and Approach}

\subsection{Important properties for layout languages and others}
\begin{itemize}
\item Verified semantics: total definition, linear complexity, change-impact analysis, ...
\item Verified implementations
\item Implementation complexity of layout lang: program analysis and code generation simplify optimization, tooling, debugging, ...
\item Implementation complexity of spec lang: desugaring eliminates costs
\end{itemize}

\subsection{Approach}
\begin{itemize}
\item language for defining tree evaluator that is restricted enough for automation support
\item push language expressiveness where needed
\item reduce language complexity via desugaring semantics
\end{itemize}


\section{The HBox Language as a Classical Attribute Grammar}
\subsection{Example tree with dynamic dependencies}
\subsection{Example static grammar instance}
\subsection{Dynamic evaluator}

\section{Desugaring Loops and Other Modern Constructs}
\subsection{Motivation: Productive Features with Simple Implementations}
\subsection{Interfaces: Lightweight and Reusable Input/Output Specifications}
\subsection{Traits: Reusing Cross-cutting Code}
\subsection{Foreign Functions: Embedded Domain Specific Language}
\subsection{Loops}


\section{Automatically Staged SIMD Memory Allocation for Rendering}
\input{chap6staging}



\section{Evaluation: Mechanized Layout Features}


\subsection{Staged SIMD Memory Allocation}
We evaluate three dimensions of our staged memory allocation approach: flexibility, productivity, and performance. First, it needs to be able to express the rendering tasks that we encounter in GPU data visualization. Second, it should some form of productivity benefit for these tasks. Finally, the performance on those tasks must be fast  enough to support real-time animations and interactions of big data sets.

\subsubsection{Flexibility}
Our staged structuring and automation approach cannot express all dynamic memory usage patterns, so it is important to validate that it works on common patterns that occur in visualization. We found the three following patterns to be important:

\begin{itemize}
\item \textbf{Functional graphics.} Functional graphics primitives used in languages such as Scheme, O'Caml, and Haskell follow the form that we used for \code{Circle}. For example, many of our visualizations use simple variants such as 2D rectangles,  3D line, and arcs.
\item \textbf{Linked view}. Multiple renderable objects can be associated with one node, which we can use for providing different views of the same data. Such functionality is common for statistical analysis software:

\begin{lstlisting}[mathescape]
render :=  @Circle(x,y,r)  + @Circle(offsetX + abs(x), offsetY + abs(y), r);
\end{lstlisting}

\item \textbf{Zooming.} We can use the same multiple representation capability for a live zoomed out view (``picture-in-picture''):

\begin{lstlisting}[mathescape]
render :=  
  @Circle(x, y, radius) 
   + @Circle(xFrame + x*zoom, yFrame + y*zoom, radius *zoom);
\end{lstlisting}

\item \textbf{Visibility toggles.} Our macros support conditional expressions, which enables controlling whether to render an object. For example, a boolean input attribute can control whether to show a circle: \code{render := isOn ? @Circle(0,0,10) : 0; }
\item \textbf{Alternative representations.} Conditional expressions also enable choosing between multiple representations, not just on/off visibility:
\begin{lstlisting}[mathescape]
render := 
  isOff ? 0
    : mouseHover ? @CircleOutline(0,0,10) 
    : @Circle(0,0,10,5) ;
\end{lstlisting}

\end{itemize}

\subsubsection{Productivity}
Productivity is difficult to measure. Before using the automation extensions for rendering, we repeatedly encountered bugs in manipulating the allocation calls and memory buffers. The bugs related both to incorrect scheduling and to incorrect pointer arithmetic. Our new design eliminates the possibility of both bugs.

One suggestive productivity measure is of how many lines of code the macro abstraction eliminates from our visualizations. We measured the impact on using it for 3 of our visualizations. The first visualization is our HBox language extended with rendering calls, while the other two are interactive reimplementations of popular visualizations: a treemap~[[CITE]] and multiple 3D line graphs~[[CITE]].


\begin{table}[ht]\caption{Lines of Code Before/After Invoking the '@' Macro}\centering\begin{tabular}{c r r r}\hline\hline \textbf{Visualization} & \textbf{Before (loc)} & \textbf{After (loc)} & \textbf{Decrease} \\ [0.5ex] \hline
  HBox & 97 & 54 & 44\% \\
  Treemap & 296 & 241 & 19\% \\
  GE & 337 & 269 & 20\% \\ [1ex] 
\hline\end{tabular}\label{table:macroreduction}\end{table}
Table~\ref{table:macroreduction} compares the lines of code in visualizations before and after we added the macros. Using the macros eliminated 19--44\% of the code. Note that we are \emph{not} measuring the macro-expanded code, but code that a human wrote.



As shown in Figure~\ref{fig:stagedallocClient}, the eliminated code is code that was introduced by staging the library calls. Porting unstaged functional graphics calls to the library, is in practice, an alpha renaming of function names.  Using the '@' macro eliminates 19--44\% of the code that would have otherwise been introduced and completely eliminates two classes of bugs (scheduling and pointer arithmetic), so the productivity benefit is non-trivial. 

\subsubsection{Performance}



\subsection{Rendering: Immediate Mode and Beyond}
\subsection{Non-euclidean: Sunburst Diagram}
\subsection{Charts: Line graphs}
\subsection{Animation and Interaction: Treemap}
\subsection{Flow-based: CSS Box Model}
\subsection{Grid-based: HTML Tables}

\section{Related Work}
\begin{itemize}
\item loose formalisms: browser impl (C++), d3 (JavaScript), latex formulas (ML)
\item restricted formalisms: cassowary and hp, UREs
\item AGs: html tables
\end{itemize}



