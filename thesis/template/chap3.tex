\chapter{A Safe Scheduling Language for Structured Parallel Traversals}
\label{chap:3}

\section{Motivation and Approach}
\begin{itemize}
\item structure is good for parallelization
\item parallelization needs checking
\item structured parallelism in layout 
\end{itemize}



\section{Background:  Static Sequential and Task Parallel Visitors}
\subsection{Sequential Visitors}  
\begin{itemize}
\item Knuth: synth and inh
\item OAG
\end{itemize}
\subsection{Task Parallel Visitors} 
\begin{itemize}
\item FNC-2 / Work stealing
\end{itemize}

\section{Structured Parallelism in Visitors} 
\subsection{td, bu, in order} (related to distributed?)
\subsection{concurrent} (old paper: unstructured within visit)
\subsection{multipass} (any old paper? unstructured within visit)
\subsection{nested}

\section{A Behavioral Specification Language}
\subsection{Formalism}

\section{Schedule Compilation}
Phrase as rewrites working in an EDSL w/ templates
\subsection{Rewrite rules}
\section{Schedule Verification}
\subsection{Overview}
\begin{itemize}
\item properties to prove: schedule followed (and complete), dependencies realizable 
\item structure of proof
\end{itemize}
\subsection{Axioms}
\begin{itemize}
\item axioms
\item examples from each
\end{itemize}
\subsection{Proof}

\section{Automatically Staging Memory Allocation for SIMD Rendering}
\input{chap6staging}

\section{Scheduling Loops}


\section{Evaluation: Layout as Structured Parallel Visits}
\subsection{Box model}
\subsection{Nested text}
\subsection{Grids}


\subsection{SIMD Rendering through Staged Memory Allocation}
We evaluate three dimensions of our staged memory allocation approach: flexibility, productivity, and performance. First, it needs to be able to express the rendering tasks that we encounter in GPU data visualization. Second, it should some form of productivity benefit for these tasks. Finally, the performance on those tasks must be fast  enough to support real-time animations and interactions of big data sets.



\subsubsection{Productivity}
Productivity is difficult to measure. Before using the automation extensions for rendering, we repeatedly encountered bugs in manipulating the allocation calls and memory buffers. The bugs related both to incorrect scheduling and to incorrect pointer arithmetic. Our new design eliminates the possibility of both bugs.

One suggestive productivity measure is of how many lines of code the macro abstraction eliminates from our visualizations. We measured the impact on using it for 3 of our visualizations. The first visualization is our HBox language extended with rendering calls, while the other two are interactive reimplementations of popular visualizations: a treemap~[[CITE]] and multiple 3D line graphs~[[CITE]].


\begin{table}[ht]
\caption{Lines of Code Before/After Invoking the '@' Macro}
\centering
\begin{tabular}{c r r r}
\hline\hline
 \textbf{Visualization} & \textbf{Before (loc)} & \textbf{After (loc)} & \textbf{Decrease} \\ [0.5ex] \hline
  HBox & 97 & 54 & 44\% \\
  Treemap & 296 & 241 & 19\% \\
  GE & 337 & 269 & 20\% \\ [1ex] 
\hline
\end{tabular}
\label{table:macroreduction}
\end{table}
Table~\ref{table:macroreduction} compares the lines of code in visualizations before and after we added the macros. Using the macros eliminated 19--44\% of the code. Note that we are \emph{not} measuring the macro-expanded code, but code that a human wrote.



As shown in Figure~\ref{fig:stagedallocClient}, the eliminated code is code that was introduced by staging the library calls. Porting unstaged functional graphics calls to the library, is in practice, an alpha renaming of function names.  Using the '@' macro eliminates 19--44\% of the code that would have otherwise been introduced and completely eliminates two classes of bugs (scheduling and pointer arithmetic), so the productivity benefit is non-trivial. 

\subsubsection{Performance}


\section{Related Work}
Lang of schedules
\begin{itemize}
\item background
\item stencils and skeletons: wavefront, ...
\item polyhedra
\end{itemize}
Schedule verification
\begin{itemize}
\item compare to OAG etc., looser dataflow/functional langs
\end{itemize}