[
{"errors": [], "paragraph": "                                                        }}}                                                                                                       ,mathescape]{#1}}\n", "spans": [[0, 180]], "file": "../../thesis/template/template.tex"}
,
{"errors": [], "paragraph": "\\title{Parallelizing the Browser: Synthesis and Optimization of Parallel Tree Traversals}\n", "spans": [[0, 90]], "file": "../../thesis/template/template.tex"}
,
{"errors": [], "paragraph": "From low-power phones to speed-hungry data visualizations, web browsers need a performance boost. Parallelization is an attractive opportunity because commodity client devices already feature multicore, subword-SIMD, and GPU hardware. However, a typical webpage will not strongly benefit from modern hardware because browsers were only designed for sequential execution. We therefore need to redesign browsers to be parallel. This thesis focuses on a browser component that we found to be particularly challenging to implement: the layout engine. \n", "spans": [[0, 97], [98, 234], [235, 370], [371, 425], [426, 548]], "file": "../../thesis/template/abstract.tex"}
,
{"errors": [], "paragraph": "We address layout engine implementation by identifying its surprising connection with attribute grammars and then solving key ensuing challenges:\n", "spans": [[0, 146]], "file": "../../thesis/template/abstract.tex"}
,
{"errors": [], "paragraph": "      We show how layout engines, both for documents and data visualization, can often be functionally specified in our extended form of attribute grammars. \n", "spans": [[0, 158]], "file": "../../thesis/template/abstract.tex"}
,
{"errors": [], "paragraph": "      We introduce a synthesizer that automatically schedules an attribute grammar as a composition of parallel tree traversals. Notably, our synthesizer is fast, simple to extend, and finds schedules that assist aggressive code generation.\n", "spans": [[0, 128], [129, 241]], "file": "../../thesis/template/abstract.tex"}
,
{"errors": [], "paragraph": "      We make editing parallel code safe by introducing a simple programming construct for partial behavioral specification: schedule sketching. \n", "spans": [[0, 146]], "file": "../../thesis/template/abstract.tex"}
,
{"errors": [], "paragraph": "      We optimize tree traversals for SIMD, MIMD, and GPU architectures at tree load time through novel optimizations for data representation and task scheduling.\n", "spans": [[0, 163]], "file": "../../thesis/template/abstract.tex"}
,
{"errors": [], "paragraph": "Put together, we generated a parallel CSS document layout engine that can mostly render complex sites such as Wikipedia. Furthermore, we scripted data visualizations that support interacting with over 100,000 data points in real time.\n", "spans": [[0, 120], [121, 235]], "file": "../../thesis/template/abstract.tex"}
,
{"errors": [], "paragraph": "To You                \n", "spans": [[0, 23]], "file": "../../thesis/template/template.tex"}
,
{"errors": [], "paragraph": "Hey you! out there in the cold \n", "spans": [[0, 8], [9, 32]], "file": "../../thesis/template/template.tex"}
,
{"errors": [], "paragraph": "Getting lonely, getting old, can you feel me \n", "spans": [[0, 46]], "file": "../../thesis/template/template.tex"}
,
{"errors": [], "paragraph": "Hey you! Standing in the aisles \n", "spans": [[0, 8], [9, 33]], "file": "../../thesis/template/template.tex"}
,
{"errors": [], "paragraph": "With itchy feet and fading smiles, can you feel me \n", "spans": [[0, 52]], "file": "../../thesis/template/template.tex"}
,
{"errors": [], "paragraph": "Hey you! don't help them to bury the live \n", "spans": [[0, 8], [9, 43]], "file": "../../thesis/template/template.tex"}
,
{"errors": [], "paragraph": "Don't give in without a fight. \n", "spans": [[0, 32]], "file": "../../thesis/template/template.tex"}
,
{"errors": [], "paragraph": "I want to thank my advisor for advising me.\n", "spans": [[0, 44]], "file": "../../thesis/template/template.tex"}
,
{"errors": [], "paragraph": "\\subsection{Why Parallel Computing}\n", "spans": [[0, 36]], "file": "../../thesis/template/chap1.tex"}
,
{"errors": [], "paragraph": "\\subsection{Why Mechanize Layout}\n", "spans": [[0, 34]], "file": "../../thesis/template/chap1.tex"}
,
{"errors": [], "paragraph": "\\subsection{Approach}\n", "spans": [[0, 22]], "file": "../../thesis/template/chap1.tex"}
,
{"errors": [], "paragraph": "\\section{Mechanizing Layout Languages with Sugared Attribute Grammars}\n", "spans": [[0, 71]], "file": "../../thesis/template/chap1.tex"}
,
{"errors": [], "paragraph": "\\section{A Scheduling Language for Structuring and Verifying Parallel Traversals}\n", "spans": [[0, 82]], "file": "../../thesis/template/chap1.tex"}
,
{"errors": [], "paragraph": "\\section{Controlling Automatic Parallelization through Schedule Sketches}\n", "spans": [[0, 74]], "file": "../../thesis/template/chap1.tex"}
,
{"errors": [], "paragraph": "\\section{The Design of a Parallel Schedule Synthesizer}\n", "spans": [[0, 56]], "file": "../../thesis/template/chap1.tex"}
,
{"errors": [], "paragraph": "\\section{Optimizing Parallel Tree Traversals for Commodity Architectures}\n", "spans": [[0, 74]], "file": "../../thesis/template/chap1.tex"}
,
{"errors": [], "paragraph": "\\section{Collaborators and Publications}\n", "spans": [[0, 41]], "file": "../../thesis/template/chap1.tex"}
,
{"errors": [], "paragraph": "\\section{Motivation and Approach}\n", "spans": [[0, 34]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We start by examining challenges for building layout languages and our high-level solution of automation through attribute grammars.  Throughout this and the remaining chapters, we focus on the design and implementation of one simple layout widget. We will show how our support of it generalizes to common layout languages and, more generally, computations over trees.\n", "spans": [[0, 132], [134, 248], [249, 369]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Important properties for layout languages and others}\n", "spans": [[0, 66]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Layout languages are some of the most common -- for one gauge, there are over 634 million websites live in 2012, with 51 million added that year~                                                                                            . Beyond the CSS and HTML languages used for webpage layout, designers also use       ~[[CITE]] for document layout, D3~[[CITE]] for data visualization, Swing~[[Swing]] for GUI layout, and even specialize within these domains such as by using markdown for text. \n", "spans": [[0, 238], [239, 500]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Popular layout languages foster designer productivity by providing abstractions that are rich and numerous.\n", "spans": [[0, 108]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The alternative is analogous to asking a programmer to write in a low-level language such as assembly: designers should not manually specify, for each element, the position on a canvas and the style. Instead, layout languages resemble constraint systems where designers  declare high-level properties. For example, the high-level program                    states that the words              and              should be rendered, and word              should follow line-wrapping rules for its positioning after             . Layout languages may provide quite complicated constraints -- for example, most document layout languages resort to defining their line wrapping rule  in a flexible low-level language. Likewise, they may provide many featuress, such as in the 250+ pages of rules for the CSS language. Adding to the sophistication, many languages support designers adding their own constraints, such as through macros in       ,  percentage constraints in CSS, and arbitrary functions in Adobe Flex~[[CITE]]. \n", "spans": [[0, 199], [200, 301], [302, 524], [525, 709], [710, 809], [810, 1018]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The richness of popular layout languages comes at the cost of of complicating their design and implementation:\n", "spans": [[0, 111]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Safe semantics.} Does every input layout have exactly one unique rendering? Are the constraints restricted enough such that an efficient implementation is feasible for low-power devices, big data sets, and fast animation? When a feature is added, does it conflict with anything of the above properties? We want an automated way to verify such properties.\n", "spans": [[0, 29], [29, 89], [90, 235], [236, 316], [317, 369]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Safe implementation.} As a layout language grows in popularity, it grows in features. Likewise, developers will port it to many platforms and optimize it, and in cases such as CSS, reimplement it from scratch. Does the implementation conform to the intended semantics? Conformance bugs for CSS plague developers~[[CITE]], and failures to match {      }'s semantics have killed multiple attempts to modernize the implementation. We want an automated way to ensure that the implementation matches the specification.\n", "spans": [[0, 34], [34, 99], [100, 223], [224, 282], [283, 441], [442, 528]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Advanced implementation.} Layout languages tend to add feature as they evolve. However, the implementation of each feature also has demands that increase with time: improved speed and memory footprint, better debugging support, etc. Browser layout engines for CSS are currently over 100,000 lines of optimized C++ code, and most rich layout languages thus far have resisted parallelization. We want automation techniques to lower the implementation burden and more aggressively target those goals.\n", "spans": [[0, 38], [38, 92], [93, 246], [247, 404], [405, 512]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Layout engine architecture.} }\n", "spans": [[0, 44], [44, 48]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Our idea is to declaratively specify layout languages and automatically compile them into an efficient implementation. At runtime, an instance of layout will be processed through the previously generated layout engine (Figure~\\ref{fig:architecture}). The compiler is responsible for checking the semantics of the layout features and, by construction, provides a correct implementation. Furthermore, instead of manually optimizing the code for every individual feature, language designers instead write generic compiler optimizations. As a similar implementation benefit, we automatically target multiple platforms for the same layout language, such as scripting languages in order to use their debuggers, and multicore and GPU languages to gain magnitudes of speedups.\n", "spans": [[0, 118], [119, 250], [251, 385], [386, 533], [534, 769]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We show that the attribute grammar formalism supports specification of layout languages. It is unclear how to encode complicated layout language features with the traditional formalism, so we support a rich form of attribute grammars and reduce reasoning about them to handling a more traditional formalism (reducer in Figure~\\ref{fig:architecture}). The remainder of this chapter introduces the high-level attribute grammar formalism, how to specify layout languages using it, and an intuition for the reduction into a lower-level formalism.\n", "spans": [[0, 88], [89, 350], [351, 543]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{For a language of horizontal boxes: (a) input tree to solve and (b) attribute grammar specifying the layout language. Specification language of attribute grammars shown in (c).%and (c) dynamic data dependencies.\n", "spans": [[0, 126], [127, 221]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\section{Background: Layout with Classical Attribute Grammar}\n", "spans": [[0, 62]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "This section describes specifying a simple layout language as an attribute grammar and two classical implementation strategies. We reuse the example throughout our work to explore various concepts.\n", "spans": [[0, 127], [128, 198]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Attribute Grammars}\n", "spans": [[0, 32]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Consider solving the tree of horizontal boxes shown in Figure~                                . As input, a webpage author provides a tree with constraints (Figure~                                    ). Only some node attribute values are provided: in this case, only the widths and heights of leaf nodes. The meaning of a horizontal layout is that, as is visualized, the boxes will be placed side-by-side. The layout engine must solve for all remaining x, y, width, and height attributes. \n", "spans": [[0, 95], [96, 202], [203, 305], [306, 406], [407, 491]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We declaratively specify the layout language of horizontal boxes,         ,  as shown in Figure~                                  , with an attribute grammar~                                 . First, the specification defines the set of well-formed input trees as the derivations of a context-free grammar. We use the standard notation~[[CITE]]. In this case, a document is an unbalanced binary tree of arbitrary depth where the root node has label            and intermediate nodes have label              . Second, the specification defines semantic functions that relate attributes associated with each node. For example, the width of an intermediate horizontal node is the sum of its children widths. Likewise, the width of a leaf node is provided by the user, which is encoded by the nullary function call $input_w()$:\n", "spans": [[0, 192], [193, 306], [307, 345], [346, 508], [509, 611], [612, 704], [705, 824]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The specification intentionally does not define the evaluation order. For example, the specification does not state whether to compute a node's width before its height. Likewise, our optimized approach will compute the attributes as a sequence of tree traversals, but the specification does not state what those traversals are. Leaving the evaluation order unspecified provides freedom for our compilers to pick an efficient parallel order. Irrespective of whatever evaluation order is ultimately used to solve for the attribute values, the statements define constraints that must hold over the computed result. Attribute grammars can therefore be thought of as a single assignment language where attributes are dataflow variables~[[CITE]].\n", "spans": [[0, 69], [70, 168], [169, 327], [328, 440], [441, 611], [612, 741]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The language of attribute grammars is defined in Figure~                        . In addition the defining the context free grammar, it supports single-assignment constraints over attributes of nodes in a production. Our example uses the following encoding. Semantic functions are pure and left uninterpreted, so, for example, we encode the addition of widths as ``                                             ''. Our program analysis techniques do not need to know the contents of the function, just that the output of a call depends purely on the inputs.  For the same reason, we encode constant values as nullary function calls. \n", "spans": [[0, 81], [82, 216], [217, 257], [258, 413], [414, 556], [558, 633]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "To specify grammars more complicated than         , we describe linguistic extensions for richer functional specifications (Section~\\ref{sec:desugaring}) and, to control the evaluation order, behavioral specification (Chapters~\\ref{chap:3} and \\ref{chap:4}).\n", "spans": [[0, 259]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Dynamic data dependencies and evaluation}. Shown for constraint tree  in Figure~ZZZ~(a). Circles denote attributes, with black circles denote attributes with resolved dependencies such as \\sched{input()}s. Thin lines show data dependencies and thick lines show production derivations. Second chart shows the dependency graph resulting from evaluating all source nodes and marking them as resolved.}\n", "spans": [[0, 59], [60, 105], [106, 301], [302, 414], [414, 416]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Dynamic data dependencies and dynamic evaluation}\n", "spans": [[0, 62]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "A simple and classic evaluation strategy is to \\emph{dynamically} compute over a tree. The evaluator dynamically follows the dynamic data dependencies between instances of attributes. The dynamic evaluation strategy is too slow for our use cases, but it introduces the key concepts of dynamic data dependencies, the dynamic semantics of attributes grammars, and the corresponding dynamic interpreter.\n", "spans": [[0, 86], [87, 183], [184, 401]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "An instance of a document corresponds to the dependency graph shown in Figure~                               . Each attribute of a tree node is either a source, meaning its value can be computed based on other known values, or it cannot be evaluated until other attribute values are known. It is a dynamic dependency graph in that each data dependency in the static code may be instantiated as multiple data dependencies given a tree at runtime. \n", "spans": [[0, 110], [111, 289], [290, 447]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The dynamic data dependency graph leads to a simple semantics for the result of evaluation. The graph corresponds to a system of equations where edges link instance variables. For example, static code                                             instantiates twice for the Figure~                               : once for each $x$ attribute with an incoming elbow connector. The value of both $x$s are constrained by distinct instances of the above constraint. If the dependency graph is a directed acyclic graph and each attribute appears on the lefthand side of exactly one equality statement (\\emph{dataflow variables}), there is exactly one solution to the system of equations.\n", "spans": [[0, 91], [92, 175], [176, 373], [374, 459], [460, 681]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "A simple procedure solves an instance of a system of equations: topological traversal. The algorithm is as follows:\n", "spans": [[0, 86], [87, 116]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Dynamic attribute grammar evaluator.} It selects attributes in a safe order by dynamically removing dependency edges as they are resolved. }\n", "spans": [[0, 53], [53, 155], [156, 158]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The algorithm literately finds an attribute whose dependencies have all been previously resolved, evaluates the attribute, and repeats. If the input graph is a directed acyclic graph, this procedure is guaranteed to terminate. The insight is that a directed acyclic graph has at least one fringe node, the loop removes them, and removing these nodes yields a smaller directed acylic graph.\n", "spans": [[0, 135], [136, 226], [227, 390]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The dynamic evaluation strategy provides a small explanation for the natural semantics, but it leaves several challenges. First, runtime manipulation of a dynamic dependency graph introduces high overheads because every dynamic dependency edge must be manipulated. Second, it is unsafe. For example, a cycle in the dependency graph causes the above evaluation strategy to get stuck, so dynamic evaluators must introduce runtime cycle check. Designers can build layout widgets that, depending on how they are invoked, fail to display!\n", "spans": [[0, 121], [122, 264], [265, 286], [287, 440], [441, 534]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{EBNF Syntax for key forms in the functional specification language.} We omit semicolons and other decorations; see the examples for more detailed forms.}\n", "spans": [[0, 84], [84, 169], [169, 171]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\section{Desugaring Loops and Other Modern Constructs}\n", "spans": [[0, 55]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The attribute grammar formalism was invented for describing semantics~[[CITE]] and before many modern constructs became mainstream: we had to design extensions for improved expressiveness and maintainability. Our extensions exploit concepts from structured, object-oriented, and functional programming. Other language designers have build such extensions as well~[[CITE]]: our challenge was to make expressive extensions that facilitate effective parallelization and do not overly complicate language and tool implementation. This section documents the language features and how they simplify implementation, and leaves performance optimization to the next chapter.\n", "spans": [[0, 208], [209, 302], [303, 525], [526, 666]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Our key insight is that pre- and post-processing supports desugaring a feature-rich attribute grammar into the canonical attribute grammar notation. Tools then operate at the most appropriate stage, such as our scheduler on the small, canonical attribute grammar representation. Likewise, our code generators take a generated schedule and relate it back to a representation from early in the preprocessing stage. Many of our features are built as explicit compiler stages, but over time, we found that declarative tree rewriting systems such as ANTLR and OMeta support automating individual stages.\n", "spans": [[0, 148], [149, 278], [279, 412], [413, 599]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The subsections below illustrate the various features and how they relate to attribute grammars. Figure~\\ref{fig:coresyntax} shows the syntax of our functional specification language. Section~\\ref{??} shows the optional extension for behavioral specification and Section~\\ref{??} for SIMD rendering macros. \n", "spans": [[0, 96], [97, 183], [184, 199], [199, 278], [278, 308]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Interfaces for tree grammars}. Subfigures show manually encoding multiple production right-hand sides, an encoding that uses a            non-terminal for indirection, and the high-level encoding using interfaces and classes.}\n", "spans": [[0, 47], [48, 242], [242, 244]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Input tree as a graph with labeled nodes and edges}. Specified in the JSON notation.}\n", "spans": [[0, 69], [70, 101], [101, 103]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Interfaces for Encoding Tree Grammars}\n", "spans": [[0, 51]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Attribute grammars are an extension to the tree grammar formalism for defining input trees, so improving the abstraction capabilities of tree grammars also aids the ability to structure attribute grammars. In particular, we found the need to support  abstracting over similar types of non-terminals. Our solution is to provide a notion of classes and interfaces. Our core extension is macro-expressible with attribute grammars and therefore reduces implementation requirements, though it is still important enough that it merits deeper compiler support. \n", "spans": [[0, 205], [206, 299], [300, 362], [363, 555]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Consider the code duplication performed when extending        with vertical boxes. The children of a             could be a horizontal box or a vertical box, and the same for the children of a vertical box. Figure~\\ref{fig:face:problem} shows that the 3 productions of        grew to be 11. The example highlights that canonical attribute grammars cannot abstract over node types. Adding a new box type requires modifying all previous box classes, and in the presence multiple children, extension suffers exponential costs. \n", "spans": [[0, 82], [83, 206], [207, 290], [291, 380], [381, 525]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "To abstract over node types, we introduce the notion of classes and interfaces (Figure~\\ref{fig:iface:clean}). Classes are similar to the productions of an attribute grammar: the class name specifies the production's lefthand side non-terminal and the children block specifies the production's righthand side. Unlike attribute grammars, an interface name is used for the righthand side rather than the class name.             and             implement interface            , so any class specified to have a             child can have a             or             child within the concrete tree. \n", "spans": [[0, 110], [111, 309], [310, 413], [426, 597]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Classes and interfaces are formally equivalent to tree grammars in the sense of a 1-to-1 correspondence between trees described by both. First, a tree grammar can be expressed with classes and interfaces by treating all productions with the same lefthand-side non-terminal as different classes belonging to the same interface. In the other direction, each interface can be expressed as a production that derives the classes, and the classes expand into productions. Figures~\\ref{fig:iface:clean} and \\ref{fig:iface:rewrite} demonstrate the correspondence for       . The induced implementation requirements are therefore slight in the sense that the construct is sugar for a pattern in the canonical attribute grammars. \n", "spans": [[0, 136], [137, 326], [327, 465], [466, 566], [567, 721]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We depart from the correspondence for the encoding of trees in two ways. First, we represent input as a tree with labeled nodes and edges. Node labels denote the class and edge labels specify child bindings. Figure~\\ref{fig:hboxjson} uses the JSON format common to dynamic languages for an instance of a tree in       . By naming children, such as             and             , we eliminate sensitivity to their order within a code block. With order sensitivity, adding a middle child               would needlessly require refactoring references to the repositioned element             . Likewise, reordering children in the input data does not require refactoring the attribute grammar.\n", "spans": [[0, 72], [73, 138], [139, 207], [208, 319], [320, 438], [439, 588], [589, 689]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Our second departure from the canonical attribute grammar encoding optimizes the data representation by eliding intermediate interface nodes. The reduction to attribute grammars suggests adding a new non-terminal for each interface, but doing so in the data representation doubles the number of nodes in the concrete tree. Making the interface pattern a language construct with compiler support eliminates associated costs, such as cutting file size for runtime parsing of big data visualizations.\n", "spans": [[0, 141], [142, 322], [323, 498]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Input tree as graph with labeled nodes and edges}. Specified in the JSON notation.}\n", "spans": [[0, 67], [68, 99], [99, 101]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Interfaces for attributes and information hiding.}\n", "spans": [[0, 61], [61, 63]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Our system provides lightweight specification annotations for different types of attributes, and coupled with the interface construct, it supports defining relationships between attributes across different classes.\n", "spans": [[0, 215]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Each static attribute is annotated with its assignment type and its embedded value type:\n", "spans": [[0, 89]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Assignment types.}\n", "spans": [[0, 31], [31, 33]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The assignment type denotes whether the input tree defines the value, such as in               , or whether the attribute grammar defines it, as in             . Assignments to an input type are illegal, and multiple assignments to a variable type are also illegal. \n", "spans": [[0, 161], [162, 267]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "If an input tree fails to provide an input attribute, a runtime error will be thrown. To still provide an interpretation of such trees, input attributes  support the annotation ''?'',  which enables pattern matching through functions                                 and                           .  Alternatively, for the common scenario of using a fixed default value, a default value can instead be defined as in                          . If the input tree does not provide the value, the default value will be automatically substituted.\n", "spans": [[0, 85], [86, 180], [180, 297], [299, 441], [442, 541]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Canonical attribute grammars can encode input attributes in two ways. First, semantic functions with no parameters encode the lack of dependencies. Second, for finite domains, the set of tree grammar productions can expand to include attribute nodes. The second encoding more faithfully describes our approach because, like our system, it feeds into an automatic tree parser generator. For each tree node, our generated parser scans for the expected set of input attributes.\n", "spans": [[0, 69], [70, 147], [148, 250], [251, 385], [386, 475]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Value types.} \n", "spans": [[0, 26], [26, 29]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The system also supports type annotations used for embeddings. Generated code typically compiles as part of a project in a more static language, such as C++, which require a static type discipline. The annotations can be user-defined, such as OpenGL's \\emph{vertex buffer object}           , which is not defined within our system.\n", "spans": [[0, 62], [63, 197], [198, 332]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Our analyzer ignores the value type annotations such as                  and                while the low-level code generator passes along the decorations              and           .  The embedded design simplifies implementation because value type checking is performed by the host language's compiler. \n", "spans": [[0, 184], [186, 307]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "In practice, we  use attribute definitions in interfaces for information hiding across classes and lightweight specification of relationships between similar classes. An attribute declared inside of a class is \\emph{local} to constraints in the class: only the class's constraints can read or write to the attribute. Conversely, declaring a \\emph{var} inside of an interface hints that it is meant to be reused by outside classes, such as part of a tree traversal.\n", "spans": [[0, 166], [167, 316], [317, 465]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Trait construct}. Adds shared rendering code to the HBox class.}\n", "spans": [[0, 34], [35, 80], [80, 82]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Traits: Reusing Cross-cutting Code}\n", "spans": [[0, 48]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "As with many object systems, we support a trait construct for cross-cutting code that should be shared across classes. It statically expands like a macro, and therefore provides no formal expressive power. For example, Figure~\\ref{fig:trait} defines how to render a rectangle given several attributes, and then adds that functionality to class            . If the language was extended with class            , the class definition of             could also use trait                 .\n", "spans": [[0, 118], [119, 205], [206, 356], [357, 485]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Input tree as graph with labeled nodes and edges}. Specified in the JSON notation.}\n", "spans": [[0, 67], [68, 99], [99, 101]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Loops}\n", "spans": [[0, 19]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We extend our language with declarative loops over the attributes of multiple nodes. They are an expressive extension over the uniform recurrence relations of [[CITE]].\n", "spans": [[0, 84], [85, 169]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The loop construct,            , specifies a block of loop body statements. It acts over a sequence of nodes declared with the same interface, such as                          in Figure~\\ref{fig:loops}. The looping order is restricted to forward iteration, though our approach generalizes to other loop orders.\n", "spans": [[0, 75], [76, 202], [203, 311]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "A statement in a loop body will execute for each element of the list. For example, the following statement assigns the attribute          the sum of the children widths:\n", "spans": [[0, 69], [70, 170]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Similar to array index notation, the suffix on righthand-side variable names for loop statements provide a restricted form of relative indexing for loops. In particular:\n", "spans": [[0, 154], [155, 170]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "       $i: the ``current'' loop step\n", "spans": [[0, 37]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "       $-: the previous loop step\n", "spans": [[0, 34]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "       $ $: the last loop step\n", "spans": [[0, 31]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Use of suffix `` $-'' in a             can be thought of as an accumulator in functional programming. \n", "spans": [[0, 103]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "One loop statement can refer to the accumulator of another, which fold statements in most languages do not support. For example, two loop counters can be intertwined:\n", "spans": [[0, 115], [116, 167]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The programmer does not manually order the statements.  For example, our system infers that the imperative code that implements the above declarations is just one imperative loop that fuses them together. The incorrect alternative of implementing the declarations as a different imperative loop for each would lead to unfulfilled data dependencies. \n", "spans": [[0, 54], [56, 204], [205, 350]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We reduced scheduling loops to scheduling canonical attribute grammars. Our insight is that, for a restricted language of relative indices, we can schedule several unrolled loop steps and generalize the schedule to the rest. Section~\\ref{sec:loopscheduling} discusses this in more detail. \n", "spans": [[0, 71], [72, 224], [225, 290]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The declarative nature of the loop construct provides two key benefits. First, coupled with the restricted indexing language, underspecification of the statement order provides freedom for automatic parallelization (Section~\\ref{sec:loopscheduling}). Second, it allows programmers to choose how to structure the program. For example, separating loop statements as above might improve legibility if they are for two different purposes, but as the computation is more intertwined, the programmer has the freedom to choose the following formulation instead:\n", "spans": [[0, 71], [72, 250], [251, 320], [321, 555]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The formulation brought the two statements together and changed their lexical order. Our language guarantees that such a refactoring does not change the semantic meaning of the code.\n", "spans": [[0, 84], [85, 183]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Embedded Domain Specific Language: Functional Rendering}\n", "spans": [[0, 69]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We designed our system for interaction with other tools and languages. A key ability is to invoke externally-defined functions, such as               of Figure~\\ref{fig:loops} for the maximum of two numbers and                    of Figure~\\ref{fig:trait} to draw a rectangle to the screen. Attribute grammars are compiled to run in some host system, such as JavaScript or OpenCL, and any function in scope to the generated code may be called.\n", "spans": [[0, 70], [71, 290], [291, 444]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Functions can be safely embedded as long as they provide a \\emph{pure} interface. In particular, the returned output should only depend on the inputs. Likewise, functions should be reentrant for use in automatic parallelization In the case of embedding in statically checked languages, the host's static checker is responsible for checking usage.\n", "spans": [[0, 81], [82, 150], [151, 347]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Visualization screenshots.} All except [[CITE]] are interactive or animated. Each one was declaratively specified with our extended form of attribute grammars and automatically parallelized. Labels describe whether GPU or multicore code generation was used.}\n", "spans": [[0, 43], [43, 93], [94, 207], [208, 274], [274, 276]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Document layout screenshots.}}\n", "spans": [[0, 45], [45, 48]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\section{Evaluation: Mechanized Layout Features}\n", "spans": [[0, 49]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We specified many common layout language features with our extended form of attribute grammars. Most examples were written with few, if any, modifications to the generated code. This experience shows that our restricted form of attribute grammars are a viable formalism for layout specification. The following subsections present highlights from our case studies in specifying layouts with attribute grammars, and the appendix contains the full code.\n", "spans": [[0, 95], [96, 177], [178, 295], [296, 451]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Rendering}\n", "spans": [[0, 23]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We found several rendering patterns to be important for many visualizations. A library of functional graphics primitives, such as                  in Figure~\\ref{fig:trait}, sufficiently augmented our attribute grammar language in order to achieve them.\n", "spans": [[0, 76], [77, 254]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{2D and 3D.} Our base primitives are 3D, and we provide 2D primitives that reduce into them. \n", "spans": [[0, 24], [24, 107]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Color.} Our functional graphics primitives take an RGBA value as input, which enables controlling hue, luminosity, and opacity.\n", "spans": [[0, 20], [20, 142]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Linked view}. Multiple renderable objects can be associated with one node, which we can use for providing different views of the same data. Such functionality is common for statistical analysis software:\n", "spans": [[0, 27], [28, 153], [154, 218]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Zooming.} We can use the same multiple representation capability for a live zoomed out view (``picture-in-picture''):\n", "spans": [[0, 22], [22, 132]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Visibility toggles.} Our macros support conditional expressions, which enables controlling whether to render an object. For example, a boolean input attribute can control whether to show a circle:                                             \n", "spans": [[0, 33], [33, 133], [134, 256]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Alternative representations.} Conditional expressions also enable choosing between multiple representations, not just on/off visibility:\n", "spans": [[0, 42], [42, 151]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Non-Euclidean: Sunburst Diagram}\n", "spans": [[0, 45]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Visualizations often require non-Euclidean layouts, such as the polar layout for the Sunburst diagram. Instead of propagating and computing over Euclidean values such as x and y coordinates as in       , the visualization can use some other.\n", "spans": [[0, 102], [103, 242]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "For example, in a sunburst diagram (Figure~\\ref{fig:renderings:sunburst}), a node should be rendered  far from the center of the chart if its level is high. In our implementation, each node transitively computes its  radius as a function of its parent's. Likewise, the center of visualization propagates from parent to child, with the root node representing the center:\n", "spans": [[0, 156], [157, 254], [255, 370]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The full example is available in Appendix~\\ref{???}.\n", "spans": [[0, 50], [50, 53]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Charting: Line Graphs and Scatter Plots}\n", "spans": [[0, 53]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We specified several types of charts with attribute grammars. For example, Figure~\\ref{fig:renderings:parlab2} depicts an X/Y scatter plot and Figure~\\ref{fig:renderings:line} depicts a line graph. We represent every data point as a leaf node in the tree. Tree traversals will compute details such as the X and Y ranges of a data set, which facilitates features such as normalization and centering.\n", "spans": [[0, 61], [62, 197], [198, 255], [256, 399]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Time series charts led to two additional encoding tricks. First, multiple time series data should often be represented at the same time, such as for a server farm, the output of each server as the days pass. Figure~\\ref{fig:renderings:ge} depicts one such multiple time series chart. Our approach was to represent each line as an intermediate node:\n", "spans": [[0, 57], [58, 207], [208, 283], [284, 349]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Second, we found the above (Section~\\ref{sec:rendering}) rendering features such as zooming, panning, and 3D representations to be important for visualizing big time series data.\n", "spans": [[0, 179]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Animation and Interaction: Treemap}\n", "spans": [[0, 48]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We declaratively encoded various animation effects with attribute grammars. For example, the fisheye effect enlarges the size of an element the closer the mouse draws near to it. Our core pattern is to encode time varying values as such the mouse position as input attributes and rerun the layout solver when the inputs change.\n", "spans": [[0, 75], [76, 178], [179, 328]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Beyond human interaction, we also support reaction to time. For example, for the treemap shown in Figure~\\ref{fig:renderings:treemap}, users may change the data set shown. Instead of immediately showing the new data set, we introduce a              attribute that an animation increments over time from 0 up to 1. The treemap interpolates the layout position based on the time, which yields a smooth transition for each data point:\n", "spans": [[0, 59], [60, 171], [172, 313], [314, 432]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Visualizations like the treemap require recompilation of most of the attributes for such animations, which can become a bottleneck and thus benefits from acceleration by our tool.\n", "spans": [[0, 180]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Grid-based: Tables}\n", "spans": [[0, 32]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We now examine one of our most difficult case studies: HTML~[[CITE]] and CSS table layout~[[CITE]]. Tables appear in  most rich document layout languages such as CSS and       , and are an instanced of \\emph{grid-based layout}, which is popular for representing layouts such as user interfaces and data tables. In conversations with commercial browser developers, we found that the proposed standards for the layout language features were reverse-engineered from earlier implementations. Furthermore, at the time of writing, two such competing standards were proposed, and with unclear notions of completeness or cases of distinction.\n", "spans": [[0, 99], [100, 310], [311, 487], [488, 635]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We found that specifying tables involved \\emph{non-linear} reasoning about \\emph{dynamic DAGs}, which we achieved by using abstract data types and  using encoding hints to perform DAG scheduling by reusing our attribute grammar tree scheduler. More dynamic formalisms such as a higher-order attribute grammars~          provide flexible alternatives, but it is not clear how to use them to address the performance criteria of the subsequent chapters.\n", "spans": [[0, 243], [244, 451]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Several challenges emerged in our analysis of HTML tables:\n", "spans": [[0, 59]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Dynamic data structure.} Layout constraints guide the mapping from a cell node to its location in the table. The computed result of attribute constraints therefore determines the underlying graph structure rather than being provided as part of the input. \n", "spans": [[0, 37], [37, 122], [123, 270]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Computing over a DAG rather than tree.} Each cell of a table has two parent nodes: its row and its column. Static attribute grammars are more typically designed for computations over trees, where each node has at most one parent. Reasoning about dependencies must support this new structure.\n", "spans": [[0, 52], [52, 120], [121, 243], [244, 306]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Non-linear constraints.} Static attribute grammars linearly bound the computation size in terms of the number of attribute instances. A more iterative process is instead used to compute dimensions for CSS's automatic table layout algorithm.  \n", "spans": [[0, 37], [37, 147], [148, 257]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Ultimately, we wrote table-specific code in the specification (see above) and the runtime, but no table-specific code in our scheduler nor code generator. For an example of logic in the specific, the specification constructs the grid data structure  by manipulating functional lists rather than just numbers. Likewise, to ensure a column's computations over its cells are scheduled after the grid is constructed, we included this dependency in the specification. \n", "spans": [[0, 154], [155, 308], [309, 464]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Our runtime edits were to use a breadth-first traversal for traversing a table and, to lookup the children of a column, search table rows for cells with the corresponding column number attribute. We did not have to add table-specific code into the synthesizer (the offline scheduling analysis) nor the code generator. \n", "spans": [[0, 195], [196, 319]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We address each problem in turn.\n", "spans": [[0, 33]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Document layout screenshots.}}\n", "spans": [[0, 45], [45, 48]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsubsection{Dynamic data structure.}\n", "spans": [[0, 38], [38, 40]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Figure~\\ref{fig:docrenderings} illustrates why the mapping from table cells to table column is dynamically computed. The placement of a cell is complicated by preceding cells that span multiple rows (\"rowspan=n\") and columns (\"colspan=n\"). Ultimately, the cell must be placed in the first column such that an earlier cell in a top-down, left-to-right ordering does not overlap it. The figure shows two important cases. First, the second cell of the first row is placed in the third column because its left sibling spans two rows: a cell's column is a function of the                attributes of its siblings to the left.  The second case is shown for the bottom right cell. Even though it is the third cell of its row in the parse tree, it is not placed in the third column. The reason is that the red dashed rectangular cell in the second row transitively impacts the placement of the cells after it. The                attributes of cells in rows above a cell further determine its column.\n", "spans": [[0, 116], [117, 239], [240, 380], [381, 418], [419, 621], [623, 674], [675, 775], [776, 902], [903, 993]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Our specification computes the column assignment as a loop over the rows. For each row, it computes what columns its cells are placed in as a function of the list of columns that are still occupied by preceding cells. The next row is given the columns that are occupied after adding cells on the current row, etc. Our specification of this behavior is interesting in that it is just calls to functional list manipulation methods written in our host language:\n", "spans": [[0, 73], [74, 217], [218, 313], [314, 459]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The                         function computes the column position during placement, so subsequent reads can look it up through another list manipulation function.\n", "spans": [[0, 163]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Specifying dynamic dependencies.}}\n", "spans": [[0, 49], [49, 52]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "A column computes the x coordinates for each cell, but column cells are not known before the last                        () call. To ensure a column computes over its cells after the mapping occurs, we explicitly declare the dynamic data dependency in the specification. First, the grid is stored in an attribute, so we simply propagate the grid to all the table nodes as an attribute (                 ). We then state the implicit data dependency (Figure~\\ref{fig:tabledyndep}. The scheduler now knows to run column computations over cells only after the                   is computed. Currently, we directly specify the constraints by enabling low-level schedule constraints (Figure~\\ref{fig:tabledyndep:raw} and Section~[[[???]]), which might be directly generated from surface syntax (Figure~\\ref{fig:tabledyndep:clean}).\n", "spans": [[0, 129], [130, 270], [271, 405], [406, 479], [480, 587], [588, 730], [730, 827]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsubsection{Computing over a DAG}\n", "spans": [[0, 37]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Computing over a table means computing over a DAG, not a tree: a cell has both a row and a column as its parents. This impacted both our runtime and our specification strategy. Demonstrating the flexibility of attribute grammars, we did not have to modify the scheduler nor the code generator. Instead, we modified the runtime and the specification.\n", "spans": [[0, 113], [114, 176], [177, 293], [294, 350]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We modified the runtime to generalize an important invariant from tree traversals to DAG traversals. In a top down traversal of a tree, a node's parent is visited before the node itself. A valid implementation for trees is depth first. However, consider a depth first traversal of a table's parse tree:\n", "spans": [[0, 100], [101, 186], [187, 235], [236, 303]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The depth-first traversal would visit the table, the row, the cell, and then the column. The cell is visited before its parent column! \n", "spans": [[0, 88], [89, 136]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Our modification was simple: we edited the runtime to visit the nodes of a table with a breadth first traversal. We kept the overall document traversal as depth first for performance reasons. Declarative schedule constraints would also support picking a breadth-first traversal (Section~\\ref{???}).\n", "spans": [[0, 112], [113, 191], [192, 295], [295, 299]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We also modified the specification to pass our attribute grammar static checker. The changes enables relaxing the scheduler's obligation to guarantee that visiting a cell's parent row and column would set all the attributes needed by the cell (unambiguous) and without conflicting with each other. For example, a column defines the             attribute of its child cell, and a row, its            . By default, our checker would rightfully reject such a specification because, if a cell has only one parent, only one of those attributes would be set.\n", "spans": [[0, 80], [81, 297], [298, 400], [401, 553]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We extended the specification language for instructing the scheduler that external code defines certain attributes:\n", "spans": [[0, 116]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The scheduler now assumes that the external code provides definitions for a column's                    and                    and a row's                    and                   . Unimportant to the synthesizer, the definitions just happen to come from elsewhere in the same specification, such as class Row defining the phantom attributes not set by Column. %If we wanted to further verify our specification, we could further specify that the assignments of a row and a column to a cell are disjoint sets that, together, hold the assignments needed for a cell, but this is unnecessary for code generation. \n", "spans": [[0, 181], [182, 360], [361, 610]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsubsection{Non-linear constraints}\n", "spans": [[0, 39]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The table specification defines a dynamically determined number of loops over a table's column to determine column widths. Such dynamism is beyond the pure static attribute grammar formalism, but our foreign function interface sufficed while still allowing overall specification and scheduling through attribute grammars.\n", "spans": [[0, 122], [123, 322]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\subsection{Flow-based: CSS Box Model}\n", "spans": [[0, 39]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Document layout languages generally feature a \\emph{flow-based} layout model where the position of one element is largely a function of the previous one. For example, line wrapping places one word after another in a paragraph, and a column will stack one paragraph after another. However, ambiguity quickly arises once constraints are added to such systems. We found that, before being able to address our interest in parallelizing the CSS language, that creating a functional specification of it was already a challenge to itself.  This section focuses on the ability to express the CSS specification, and defers discussion of functional correctness (Chapter~??) and safe parallelization (Chapter~??).\n", "spans": [[0, 153], [154, 279], [280, 357], [358, 531], [533, 662], [662, 700], [700, 703]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Challenging specification, the CSS standard provides only a few explicit formulas such as                                                             for the shrink-to-fit calculation. It generally does not fully define the intrinsic dimensions to plug into the formula. We incorporated what we found, and for the rest, spent significant time reengineering the semantics by examining the standard and experimenting with existing browsers. While it is unclear how to evaluate faithfulness, we encoded enough features to render a resemblance of the Wikipedia main page (Figure~\\ref{fig:rendering:css}) and a popular blog.\n", "spans": [[0, 184], [185, 270], [271, 438], [439, 620]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Our attribute grammar describes the layout solving features of the informally written CSS 2.1 standard. It also includes automatic table layout, which was only more completely defined in later CSS standards. It does not include preprocessing steps, such as the CSS cascade that annotates the HTML tree with attributes, nor anonymous content generation, which normalizes the annotated tree to guarantee that spans of sibling nodes are homogeneous. The former is largely a combination of a simple extension to regular expressions and prioritization constraints. We found we could include parts of the cascade in our approach, such as handling units, and thus do.  Normalization is a bottom-up tree rewriting pass, and an implementation optimization avoids performing it before layout and instead makes it an on-demand part of layout solving. We primarily focus in the core box model: normal flow (blocks and inlines), out of flow (relative and absolute positioning, floats), and borders, padding, and margins.\n", "spans": [[0, 103], [104, 207], [208, 446], [447, 559], [560, 660], [662, 839], [840, 1008]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Our specification largely follows the style of the above grammars. Part of the intuition for the feasibility of specifying CSS in this way is that CSS was designed with restrictions that avoid requiring slow evaluation with techniques such as iterative constraint solving. In our encoding, each CSS display type is represented by one or more classes in our system. CSS's normalization algorithm largely leads to our set of interfaces, such as grouping the               and                     display types under interface              . We make heavy use of traits and interfaces, which compromise 23 % and 32 % of the code, respectively. The automatic table layout algorithm was an extension of the above techniques. Finally, similar to the issue with table cells having two parents, a row and a column, out of flow elements also required encodings to support DAG behavior. \n", "spans": [[0, 66], [67, 272], [273, 364], [365, 538], [539, 640], [641, 719], [720, 878]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "Several differences distinguish our experience with specifying CSS layout from the other case studies. Many features were difficult to specify because of many cases or cross-cutting in their semantics. Discussed in Chapter~         , we rely upon automatic checking to assist development, and discussed in Chapter~         , we specify schedule sketches to improve compiler speed and more quickly experiment with parallelization schemes. To further simplify development, we wrote several increasingly large specifications and manually integrated them.\n", "spans": [[0, 102], [103, 201], [202, 437], [438, 552]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "One particularly challenging feature to disentangle relates to ambiguity. CSS  solves seemingly inconsistent input constraints instead of returning an error. For example, if        was extended to support input heights on intermediate nodes, the following conflict would require a graceful interpretation rather than refusing to render:\n", "spans": [[0, 73], [74, 157], [158, 337]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "By the original attribute grammar, the outer               should be the size of the biggest child, which would be 500. However, that conflicts with the input constraint of the outer box only being 5 tall. Our CSS grammar inspects for the presence of input attributes and prioritizes them. The analogous resolution for the        example is the following:\n", "spans": [[0, 119], [120, 205], [206, 289], [290, 356]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The grammar uses \"5\" and \"500\" because they were explicitly specified instead of solving for them.  \n", "spans": [[0, 101]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We found other features to be difficult because they purposefully stray from the direct mathematical interpretation. For example, CSS supports input constraints where a node's width is defined as a proportion of its parent's. If we na \"{i}vely extended        with such a feature, evaluation of the following layout would lead to a degenerate solution:\n", "spans": [[0, 116], [117, 225], [226, 353]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "The root node shrinks to fit the middle node, but the middle node must be 50 % of the parent. Direct interpretation leads to a solution of 0 for both widths, but CSS instead leaves the result up to the layout engine implementation. The first reason is that the result looks unappealing: the containers of the leaf node do not appear. The second reason is that, while iterative solvers may avoid some such situations, but at the expense of performance. Implementations instead use non-iterative heuristics, but as seen with tables, implementors struggle to understand them.\n", "spans": [[0, 93], [94, 231], [232, 333], [334, 451], [452, 573]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "In summary, our attribute grammar formalism was sufficiently flexible to specify a non-trivial subset of the widely used CSS language. We encountered several key difficulties, and discuss those relating to correctness, safe and effective parallelization, and compiler speed in Chapters~\\ref{???} and~\\ref{???}.\n", "spans": [[0, 134], [135, 294], [294, 308], [308, 311]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "\\section{Related Work}\n", "spans": [[0, 23]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      loose formalisms: browser impl (C++), d3 (JavaScript), latex formulas (ML)\n", "spans": [[0, 81]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      restricted formalisms: cassowary and hp, UREs\n", "spans": [[0, 52]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "      AGs: html tables\n", "spans": [[0, 23]], "file": "../../thesis/template/chap2.tex"}
,
{"errors": [], "paragraph": "We now introduce a static scheduling language for parallel computations over a tree such as those seen in layout. A compiler takes an attribute grammar (the functional specification) and its schedule and outputs an implement, i.e., a layout engine. For now, we ignore the source of the schedule. Beyond presenting the language and compilation strategy, we show how to verify functional and behavioral (parallel) correctness, introduce the first parallel schedule for a large subset of CSS, and show how, on GPU tree computations, memory may be dynamically allocated quite efficiently.\n", "spans": [[0, 113], [114, 248], [249, 295], [296, 585]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The goal of our language for traversals over trees is to benefit from high-performance computing techniques  commonly used for stencils over grids. Common for physical modeling, a stencil computation is one where a kernel only reads and writes to a limited set of nodes, there are many kernels, and the data dependencies between kernels lead to traversal patterns such as a wavefront. Many variants of stencils exist. The enthusiasm for them stems from programmers or stencil compilers being able to exploit knowledge of their structure to effectively optimize for use of cache lines, memory, parallel processors, and other resources. Similar techniques are known for trees, and the next chapter introduces additional ones.\n", "spans": [[0, 147], [148, 384], [385, 417], [418, 634], [635, 724]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Our first challenge in this chapter is to restrict the scheduling language enough to facilitate optimization while still providing the flexibility for expressing  document layout and data visualization workloads. Finding parallelism in CSS is already novel,  so being further able to optimize it with techniques associated with small formulas for physical models is surprising. We found that, while layout computations have too many data dependencies to be solved with one simple tree traversal, sequences of 3--5 traversals often suffice for data visualizations and 9 for CSS. Our scheduling language therefore consists of traversal patterns, such as parallel top down (\\emph{preorder}) traversal of the tree, and ways of combining them, such as in a sequence. One especially representative case study of matching restrictions with flexibility was in our study of  visualizations: dynamic memory allocation on a GPU is generally a bottleneck, but we used a sequence of tree traversals for parallel allocation of render buffers for each node.\n", "spans": [[0, 212], [213, 377], [378, 577], [578, 761], [762, 1043]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Another artifact of layout specifications being magnitudes bigger than stencil formulas is that the correctness concerns change. For stencil computations, the verification challenge lies more in correctly optimizing the implementation of a traversal schedule. Layout computations encounter a challenge before that point: the size of the functional specification and the ensuing tangle of data dependencies require ensuring  that the parallel schedule itself is safe to implement. We use a variant of existing static dependency analyses of attribute grammars to verify that the schedule is race-free. \n", "spans": [[0, 128], [129, 259], [260, 479], [480, 601]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The dependencies that complicate reasoning about correctness of parallel code actually also complicate sequential code. Our use of static analysis for the attribute grammars leads to an important result for layout languages: we show how to statically verify three important properties about them.  \n", "spans": [[0, 119], [120, 299]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Totality} The layout language defines a solution for every syntactically well-formed input tree; it is unambiguous. \n", "spans": [[0, 131]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Determinism} As discussed  in the previous paragraph, parallelization is safe.\n", "spans": [[0, 93]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Linearity (Single Assignment)} Every attribute is assigned to exactly once. Layout languages often perform \\emph{reflow} to iteratively solve constraints or incremental computation, so this property bounds the need for it. \n", "spans": [[0, 89], [90, 238]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The first property demonstrates the ability to reason about \\emph{functional correctness} and the last two about \\emph{behavioral correctness}. Put together, we verify that a language is unambiguous, supports parallelization, and with bounded asymptotic complexity.  \n", "spans": [[0, 143], [144, 268]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\section{Language of Static Schedules}\n", "spans": [[0, 39]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "This section focuses on defining our full language of traversal schedules. It is the input for our code generators. Programmers either do not specify the schedule in practice due to our automation support, or use the \\emph{sketching} extension (Section~\\ref{sec:holes}) for more succinct partial specification.\n", "spans": [[0, 74], [75, 115], [116, 311]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Statically scheduled evaluation departs from the dynamic evaluation strategy of Chapter~\\ref{chap:2}. Static scheduling solves the performance problem of dynamic evaluation repeatedly manipulating the data dependencies of every attribute at runtime. For example, what would be a direct sequence of arithmetic statements in a static language becomes an interleaving of graph manipulations and arithmetic with the dynamic evaluator. The runtime scheduling overhead for evaluating all the statement is (at least) linear in the size of the data dependency graph. \n", "spans": [[0, 101], [102, 249], [250, 430], [431, 560]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Instead, a schedule statically specifies most of the scheduling decisions.  It specifies a sequence of tree traversals and the order of statements to use within each traversal. During a traversal at runtime, the order of nodes to traverse is based on the traversal pattern, such as top-down, rather than by inspecting data dependencies. Likewise, the statements to execute for a node are looked up based on the node's type rather than by data dependencies.  Our approach is a more compositional variant of others. Our flexibility requirements led to focusing on the ability to compose different types of traversals, such as by sequencing and nesting.\n", "spans": [[0, 74], [76, 176], [177, 336], [337, 456], [458, 513], [514, 651]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Sequentially scheduled and compiled layout engine for \\hlang{}.}}\n", "spans": [[0, 80], [80, 83]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Sequential Schedules}  \n", "spans": [[0, 36]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We start by examining how to specify a safe static schedule for        that respects any possible dynamic dependencies (Figure~\\ref{fig:deps:full}).\n", "spans": [[0, 149]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Figure~\\ref{fig:hboxseq} shows a sequential implementation of        decomposed into several pieces. The layout engine solves an input tree over a sequence of two traversals (Figure~\\ref{fig:hboxseq:sequence}). The first traverses the tree in postorder, meaning from the leaves up to the root (''bottom-up'') and the second performs are preorder traversal, meaning from the root down to the leaves (''top-down''). Figure~\\ref{fig:hboxseq:traversals} provides a sample implementation of generic traversal code. During a during traversal, each node is \\emph{visited} exactly once in order to compute the attributes whose dependencies have been satisfied. Figure~\\ref{fig:hboxseq:compiled} shows that the first pass computes widths and heights and the second pass computes the x and y positions.\n", "spans": [[0, 100], [101, 210], [211, 413], [414, 509], [510, 652], [653, 793]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The example follows a static schedule rather than manipulating a dynamic data dependency graph. The sequence of traversal invocations and the code used for the different cases for each traversal's visitor determine the schedule. Each traversal now only performs dynamic scheduling in the sense of maintaining a stack for recurring down the tree, which is a cost proportional to the number of nodes rather than the size of the dynamic dependency graph between attributes. In practice (Chapter~\\ref{chap:6}), our compiler and runtime optimizations even eliminate the example's implicit use of a call stack.\n", "spans": [[0, 95], [96, 228], [229, 470], [471, 605]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The decompose the schedule into several types of policy fragments. First, the schedules involves a \\emph{sequence} of  \\emph{two different types} of traversals:\n", "spans": [[0, 66], [67, 161]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Just one bottom-up traversal cannot compute all the attributes, such as all the x and y attributes that flow downwards (Figure~\\ref{fig:deps:full}), so the schedule may require multiple types of traversals and in a careful order.  Furthermore, within a traversal, the schedule specifies different orders of statements for different types of nodes. Consider the following fragment:\n", "spans": [[0, 229], [231, 347], [348, 381]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The schedule specifies that            $_2$          can (and should) be immediately evaluated after            $_1$          without fear of unsatisfied data dependencies for any of its right-hand side terms. In summary, we see three parts to a schedule: the staging of traversals, the node visit order for every individual traversal, and the statement order for different types of nodes within a specific traversal.\n", "spans": [[0, 209], [210, 418]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We abstracted the three aspects of a schedule into a scheduling language (Figure~\\ref{fig:hboxparallel}). For example, the schedule for the above computation would be appear as:\n", "spans": [[0, 105], [106, 178]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "It specifies a sequence ('';'') of two traversals of node visit order                  and                . For each type of node visited within a traversal, the schedule specifies the sequential sequence of attributes to evaluate. We note that, due to the desugaring of our class system in Section~\\ref{sec:desugaring}, the dispatches in the above examples are based on grammar productions in the desugared representation. In terms of the fronted language, the dispatches are based on node class.\n", "spans": [[0, 107], [108, 231], [232, 423], [424, 498]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Generally, a single attribute grammar may be scheduled in many ways. For example, the width and height computations share no dependencies, so the first postorder traversal might be partitioned into two postorder traversals:\n", "spans": [[0, 68], [69, 224]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Rescheduling in this way may improve performance on small devices with little memory because the schedule cuts the working set size in half for each traversal. Note, however, that the schedule only optimizes execution; it does not change the result of evaluation.\n", "spans": [[0, 159], [160, 264]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Nested traversal for line breaking}. The two paragraphs are traversed in parallel as part of a preorder traversal. A sequential recursive traversal places the words within a paragraph. Circles denote nested regions and arrows show data dependencies between nodes and/or regions.}\n", "spans": [[0, 53], [54, 131], [132, 201], [202, 295], [295, 297]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Sequential execution supports a traversal type that can compute more than                  or                , which we call a                  traversal (Figure~\\ref{fig:hboxseq:traversals}). We use a recursive traversal, for example, for line breaking in our document layout case study. Consider inserting line breaks into the following stylized paragraph of XML strings (Figure~\\ref{fig:nested}):\n", "spans": [[0, 192], [193, 288], [289, 400]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Due to                , the paragraph may need a line break between ``ipsum'' and ``dolor.''  Identifying the line break position involves visiting the subtree                               ; the resulting line break position is a data dependency influencing line breaks in the remainder of the text. The sequence of arrows in the big circle of Figure~\\ref{fig:nested} show a trace of performing a recursive traversal over the paragraph. The traversal visits a node $n$, then visits $n$'s first child, revisits $n$, and repeats this process for the remaining children before returning to the parent. \n", "spans": [[0, 90], [90, 300], [301, 437], [438, 601]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The relationship between                  traversals and                  and                 merits examination. First, a sequence of a preorder traversal followed by a postorder traversal may be merged into one recursive traversals. Traversing a tree induces overhead costs, so such fusion may be beneficial. The reverse  relationship is not true, however. As happens with the case of line breaking, long-running sequential dependencies may prevent splitting a recursive traversal into a preorder and postorder traversal. These dependencies arise because the the same node is visited multiple times in a traversal: once before a child subtree is traversed and again after. The result of computing over one subtree may therefore be used to compute another, which supports long-running sequential dependencies. \n", "spans": [[0, 113], [114, 234], [235, 310], [311, 358], [359, 523], [524, 674], [675, 812]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Scheduled and compiled layout engine for \\hlang{}.}}\n", "spans": [[0, 67], [67, 70]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Parallel Traversal}. Shown for constraint tree  in Figure~ZZZ~(a). Circles denote attributes, with black circles denoting attributes with resolved dependencies such as \\sched{input()}s. Thin lines show data dependencies and thick lines show production derivations. First diagram shows dependencies followed by first traversal, and second for the following traversal.}\n", "spans": [[0, 37], [38, 83], [84, 281], [282, 383], [383, 385]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Parallel Schedules: Same Traversal}\n", "spans": [[0, 48]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "A schedule exposes structured parallelism both within a traversal and across them. \n", "spans": [[0, 84]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "For an example of parallelism within a traversal, the first postorder traversal for        features latent parallelism. The widths and heights for one subtree can be computed independently of the widths and heights of another distinct subtree. Figure~\\ref{fig:depsparallel:postorder} shows an example where different (logical) threads may compute on the leaf nodes and implicit barriers force a join at every intermediate node. Likewise, the second traversal (Figure~\\ref{fig:depsparallel:preorder}) may be changed to a parallel preorder traversal where ever intermediate node acts as a logical fork. Figure~\\ref{fig:hboxparallel:traversals} depicts na \"{i}ve parallel implementations using Cilk's~                       and             primitives. We formulate the schedule by changing the specification from                  and                 to                and               (Figure~\\ref{fig:hboxparallel:schedule}).\n", "spans": [[0, 119], [120, 243], [244, 427], [428, 600], [601, 748], [749, 925]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Our \\emph{nested} traversal feature supports exploiting parallelism within a traversal even if some nodes require sequential evaluation.  With it, the tree is partitioned into an outer region and disjoint inner regions.  The outer and inner regions are evaluated with different traversals, and both may exploit parallelism.  We can think of the inner regions as macro-nodes that are evaluated in full (with their particular traversal type) when the outer traversal encounters them.  \n", "spans": [[0, 136], [138, 219], [221, 323], [325, 484]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "To motivate the need for nested traversals, we revisit line breaking.  Even though line breaking of a single paragraph is sequential, distinct paragraphs of text can be handled in parallel.  To avoid locally sequential computations from forcing the entire tree traversal to be sequential, we allow the outer region to be parallel, while each paragraph forms an inner region that is handled with the sequential recursive traversal. Figure~\\ref{fig:nested} shows how parallel evaluation may be used to compute across different \\sched{recursive} paragraphs. Likewise, it shows a hypothetical             subtree that uses parallel postorder evaluation for traversing its subtree as soon as the outer parallel preorder traversal reaches it.\n", "spans": [[0, 69], [71, 189], [191, 430], [431, 554], [555, 737]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "To partition a tree into regions, the schedule maps each grammar production (and thus each node of the tree) to a traversal type in the synthesized schedule.  A subtree composed from nodes of the same traversal types form an inner region.  For example, a nested traversal of paragraphs with sequential traversals of nested text subtrees is described as follows: \n", "spans": [[0, 157], [159, 238], [240, 363]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Parallel Schedules: Across Travesals}\n", "spans": [[0, 50]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We may exploit parallelism across traversals as well. For example, just as we created a different but functionally equivalent sequential schedule for       , we can do the same manipulation to yield a new parallel schedule:\n", "spans": [[0, 53], [54, 224]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The ``$||$'' construct specifies that one traversal may be run concurrently with another. Neither traversal traversal depends on attributes written by the other, so the parallelizaton is safe. Even if we cannot exploit parallelism within a traversal, using ``$||$'' enables us to exploit parallel across them. \n", "spans": [[0, 89], [90, 192], [193, 311]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Compilation}\n", "spans": [[0, 25]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Compilation only requires an attribute grammar and the schedule. The traversal staging                                 directly translates to the executable fragment in Figure~\\ref{fig:hboxseq:sequence}. Likewise, the mapping from traversal productions to statement sequences, such as             $                    $                          }, directly translate to the visit functions of Figure~\\ref{fig:hboxseq:compiled}. The translation matches an attribute in the schedule with the lefthand side attribute of an equation in the attribute grammar and outputs the full assignment statement in its place. \n", "spans": [[0, 64], [65, 203], [204, 427], [428, 611]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Our code generation pipeline is further complicated but conceptually similar. The schedule is combined with the attribute grammar to form an intermediate representation, and different code generators target different backends such as JavaScript, OpenCL, and C++. Furthermore, some of the reductions of Section~\\ref{sec:desguaring} require augmenting or rewriting the intermediate representation, such as reinserting loops that were unrolled during scheduling (Section~\\ref{???}). Our end-to-end compiler design is slightly different due to the synthesis algorithm (Chapter~\\ref{chap:4})  and schedule autotuning (Section~\\ref{sec:schedtuning}), but code generation for a schedule follows a more conventional process.\n", "spans": [[0, 77], [78, 262], [263, 479], [480, 717]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\section{Automatically Staging Memory Allocation for SIMD Rendering}\n", "spans": [[0, 69]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\section{Statically Scheduling Loops}\n", "spans": [[0, 38]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Many of the difficulties in computer science stem from handling loops.  Our question is how to statically schedule uses of the declarative construct of Section~\\ref{subsec:loops}. The construct extends the language of statements to include non-nested loops, and an attribute computed in one step of one loop may depend on that of another. To avoid implementation complexity, we want to schedule loops through a reduction to a language without loops. Our insight is that we can finitely unroll any loop a fixed number of times in such a way that its schedule generalizes to a loop over an arbitrary number of items at runtime.\n", "spans": [[0, 70], [72, 179], [180, 338], [339, 449], [450, 626]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Our problem is distinct from that of classical attribute grammar languages for two reasons. First, modern formalisms focusing on expression generally rely upon dynamic scheduling. Second, for the formalisms that provide static scheduling, loops would be over the tree rather than as part of the statement language. For example, a list of values would be encoded as a chain:\n", "spans": [[0, 91], [92, 179], [180, 314], [315, 374]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The position of a number in a                  chain corresponds to the tree level, and so a loop over them will occur as multiple steps of a global tree traversal. However, such loops are generally localized and one instance should be computable as part of the same step. Local loops simplify parallelization and can reduce the number of required tree traversals. Finally, local loops increase the expressivity of a traversal by eliminating what would otherwise represent a non-local dependency that could challenge scheduling as a structured tree traversal. \n", "spans": [[0, 164], [165, 272], [273, 364], [365, 561]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "In terms of the above encoding, our support of loops corresponds to extending ordered attribute grammars with a Kleene star. We could use it to modify the above program to keep a list of values local to a production:\n", "spans": [[0, 124], [125, 217]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The language of constraints are recurrence relations~         . Attribute dependencies may lead to subtle interactions with traversal patterns, however. For example, in a                  traversal (Section~\\ref{subseq:seqscheds}), each loop step may requiring recurring through a subtree before performing the loop step for the next subtree.\n", "spans": [[0, 63], [64, 152], [153, 343]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Our approach is to divide the problem into two steps. First, we transform an attribute grammar with loops into one without them by unrolling several steps of the loop. Second, after scheduling the loopless grammar, we recover loops from the schedule. Our approach guarantees that, if the synthesizer reports a loopless schedule, dependency-preserving loops will be recovered from it.\n", "spans": [[0, 53], [54, 167], [168, 250], [251, 384]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Loop scheduling}.The loops may be scheduled for the same traversal if attributes          and          are available.}\n", "spans": [[0, 134], [134, 136]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Reduction to OAGs by Unrolling}\n", "spans": [[0, 44]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We show how to schedule the following loop:\n", "spans": [[0, 44]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Our reduction unrolls the loop into 4 steps ($0$, $1$, $2$, and $n$):\n", "spans": [[0, 70]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "           ~child : [ interface ] ~           &            child0, child1, child2, child            : interface \n", "spans": [[0, 113]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "           child.fld :=               ~ e_{             ,fld} ~ .. ~ e_                         &            \n", "spans": [[0, 110]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "& child0.fld =           ~e_                                                                          ~             + e_{             ,fld}; \n", "spans": [[0, 142]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "& child1.fld =           ~e_             ~             + child0.fld;\n", "spans": [[0, 69]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "& child2.fld =           ~e_             ~             + child1.fld; \n", "spans": [[0, 70]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "& childn.fld =           ~e_             ~                      + child2.fld;\n", "spans": [[0, 78]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "           ~child $ $.fld ~                  &            child           . fld\n", "spans": [[0, 75], [76, 80]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "           ~child $i.fld                   &             child      .fld\n", "spans": [[0, 73]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "           ~child $          .fld              &             child0.fld\n", "spans": [[0, 72]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "           ~child $          .fld              &             child1.fld\n", "spans": [[0, 72]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "           ~child $          .fld                       &             child2.fld\n", "spans": [[0, 81]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Rewrite Rules for Loop Reduction}. Cases of $                           $ that simply recur are elided.}\n", "spans": [[0, 51], [52, 120], [120, 122]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The reduction performs several rewrites that unroll loops and then substitute variable names in the unrolled statements (Figure~\\ref{fig:loopreduction}). The first key property that the unrolling preserves is that the dependencies are preserved. The unrolling does this in several ways:\n", "spans": [[0, 153], [154, 245], [246, 287]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Schema unrolling.} It unrolls every declaration ``                        '' into the following form:\n", "spans": [[0, 31], [31, 116]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Substitution.} The first step of a loop unfolds by replacing references of the form ``                  '' to use the initial value specified in the first part of a ``           '' expression. Likewise, step 1 will substitute the reference with ``                 '', and ``                  '' for ``                 ''. Finally, it replaces every reference to last value ``                  '' with ``                ''.\n", "spans": [[0, 27], [27, 206], [207, 335], [336, 437]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Forward Loop Direction.} The rewriting enforces a forward loop direction by making                   depend on                  ,                   depend on                  , etc. The dependencies simplify later analysis by eliminating concerns in safely reordering steps of a loop. To support an alternative loop order, such as backwards, these dependencies would be elided and the recovery algorithm would be perform more reasoning.\n", "spans": [[0, 37], [37, 195], [196, 298], [299, 451]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The result of the rewriting is a canonical attribute grammar without loops. Our full implementation differs in two significant ways. First, it performs static checks such as that the             initialization expression does not refer to step variables ``                  '' nor                   . Likewise, statements looping over one collection are checked for references to intermediate elements of another. Second, the rewriting supports loops that may temporarily escape as part of a                  traversal. Each loop step over an element may require traversal into the element's subtree, so we expand child attributes with a local and transfer version in order to reason about safe placement of the recursive call. \n", "spans": [[0, 75], [76, 132], [133, 300], [301, 413], [414, 519], [520, 729]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Recovery by Commuting Abstractions}\n", "spans": [[0, 48]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "If the rewritten grammar can be scheduled, so can the original grammar with loops. We extract loops from the scheduled grammar and guarantee that any dependency in the original grammar is safely obeyed by the extracted loops. A difficult part of the guarantee is proving that the procedure for recovering loops from the schedule will not get ``stuck.'' This section describes the loop recovery process and its correctness.\n", "spans": [[0, 82], [83, 225], [226, 350], [350, 423]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The algorithm first rearranges loop statements into distinct blocks. The scheduler may interleave statements from loops over distinct sets of children, but code generation needs them to be separated.  Likewise, the algorithm must rearrange all non-loop assignments to fit between loop blocks. The procedure iteratively partitions a sequence of attributes into several subsequences until it reaches a normal form and can proceed nor further.\n", "spans": [[0, 68], [69, 199], [201, 292], [293, 441]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "For each iteration, the algorithm takes a sequences of attributes starting with ``                 '', which represents the beginning of a loop. It partitions the attributes following it into those that must occur before the loop, after the loop, or during it. The loop's partition is then ready for code generation, and the algorithm repeats on the other two partitions. As the algorithm finalizes a loop with at least one attribute in each step, we guarantee that the algorithm terminates.\n", "spans": [[0, 144], [145, 260], [261, 371], [372, 492]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The partitions for one step of the algorithm are determined by applying the following three rules:\n", "spans": [[0, 99]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Extract non-loop assignments from a loop}. The beginning of a loop corresponds to an assignment to ``                 '' and the end by an assignment to ``                 ''. Assignments to non-loop variables that occur within the loop range are moved to be before the beginning of the loop. They are moved out in case multiple statements are scheduled for the same loop and some of them depend on the non-loop variables. All non-loop assignments in a loop range are moved out with their relative ordering preserved.\n", "spans": [[0, 56], [57, 189], [190, 306], [307, 436], [437, 532]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Moving a non-loop assignment to before the loop is safe. If the assignment depended on a loop variable, that variable could only have been the final one (                  ), and the scheduler would not have placed the assignment inside of the loop range. Likewise, if a loop statement depends on the non-loop assignment, moving the assignment earlier preserves the ordering. Finally, moved assignment statements may have mutual dependencies, so maintaining their relative ordering during the movement preserves any read-after-write dependencies.\n", "spans": [[0, 56], [57, 255], [256, 375], [376, 547]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The process is guaranteed to terminate. First, moving statements out of one loop completes in time linear in the size of the range of the loop. Second, the finite number of loops means that the process only repeat a finite number of times because movement only occurs in one direction.\n", "spans": [[0, 39], [40, 143], [144, 286]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Separate loops over different collections} The algorithm iteratively separates loops over different collections. First, it detects mutually dependent statements that must be scheduled as part of the same loop. Then, it examines the loop span for statements belonging to another type of loop and moves them either to before or after the base range of mutually dependent statements.  The moved statements maintain their ordering relative to other statements moved to the same side of the range.\n", "spans": [[0, 126], [127, 223], [224, 394], [396, 507]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The complexity of the operation stems from mutually dependent loop variables. For example, the following code must be scheduled into the same loop:\n", "spans": [[0, 77], [78, 148]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The partial order for the resulting schedule is ``                                          ''. If ``         '' is scheduled as ``                                    '', the ``        '' computations do not depend on ``        '' nor ``        '' ones, but not vice-versa. The ``        '' loop must be moved ahead. Doing so is safe relative to ``             '' because ``        '' statements cannot depend on them. Furthermore, if ``        '' is dependent on other statements in the range, those would also be moved with it, such as seen with ``        ''.  For the remaining statements, ``              '' do not depend on them and the algorithm moves them after.\n", "spans": [[0, 95], [96, 273], [274, 316], [317, 418], [419, 561], [563, 670]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The algorithm terminates because it recursively operates on successively smaller partitions: statements moved earlier, the current loop range, and statements moved after. \n", "spans": [[0, 172]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Separate staged loops over the same collection} Loops over the same collection may still need to be separated. Consider the following loop:\n", "spans": [[0, 124], [125, 154]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "A valid resultant schedule would be the same as the above case. In fact, the same reasoning as applied above applies to this case. For most of the above reasoning, only the loop steps matter. \n", "spans": [[0, 63], [64, 130], [131, 193]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Due to dependencies across statements being moved before or after a loop, each partitioning step performs all of the above separations. The relative order of statements moved out of a loop is thereby preserved. \n", "spans": [[0, 135], [136, 212]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Once the partitioning completes, the code generator receives a a list of blocks. Each block is for loop statements or non-loop statements. The code generator handles blocks of non-loop statements as usual. A block of loop statements will translate into a single loop. For example, the above code example code generates as follows:\n", "spans": [[0, 80], [81, 138], [139, 205], [206, 267], [268, 331]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Note that translation of references of the form ``              $-$           '' require tracking the loop step in order to pick whether to use the initial value or the previous node's value.\n", "spans": [[0, 192]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\section{Verification}\n", "spans": [[0, 23]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We automatically check an attribute grammar and its schedule for safety. This section focuses on two aspects of our approach: the properties to verify and the modular design of the verification procedure. The properties are significant in that they cover both functional and behavioral correctness, and are typically desired but not proven for layout languages and pattern programs. Furthermore, we check the properties through axiomatic reasoning parameterized by a local dependency analysis. This proof structure simplifies extending the language of statements and of schedules as most additions correspond to an isolated and com posable axiom. Later, in Chapter~\\ref{chap:4}, we show a simple approach to changing the verifier into a synthesizer and thereby achieve fully automatic or computer-assisted parallelization.\n", "spans": [[0, 72], [73, 204], [205, 382], [383, 493], [494, 646], [647, 823]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Our approach automatically checks three properties. \n", "spans": [[0, 53]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Totality} The specification defines one and only one solution for every well-formed input tree. \n", "spans": [[0, 111]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Determinism} The schedule evaluates the constraints of the attribute grammar without any data races.\n", "spans": [[0, 115]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Linearity (Single Assignment)} Every attribute is assigned exactly once. Layout languages often perform \\emph{reflow} to iteratively solve constraints or incremental computation, verifies that reflow is strictly an optimization.\n", "spans": [[0, 86], [87, 243]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "In this chapter, we illustrate how to check race freedom. The check for linearity is similar , and totality is a consequence of the determinism and linearity properties.\n", "spans": [[0, 57], [58, 170]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We focus on a modular checking strategy for two reasons. First, we encountered implementation challenges without it. Our initial attempts to adapt the OAG~           algorithm, which is a search over a global dependency graph, suffered from many implementation bugs before we abandoned it. Our new approach instead decouples verification from synthesis and pattern checking from dependency analysis. Second, challenging our OAG implementation and the basic premise of our approach, we need to support adding new types of traversals. New schedule combinators, such as nested traversals, and individual patterns, such as recursive, should be simple to add as new types of parallel patterns are understood. Adding a parallel pattern should not require refactoring the entire verifier or synthesizer. Our new approach phrases each pattern as an independent axiom and automatically incorporates it into the checking procedure.\n", "spans": [[0, 56], [57, 116], [117, 289], [290, 399], [400, 532], [533, 703], [704, 796], [797, 922]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Axiomatic Checking for Modularity and Correctness}\n", "spans": [[0, 63]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Correctness axioms for checking an entire schedule are in Figure~\\ref{fig:deductions}. The judgements recursively check a composition of traversals until reaching the traversal-specific checks of Figure~\\ref{fig:checkers}. Checking tames worst-case time linear in the number of attributes and the number of their local dependencies. As a reminder, Figure~\\ref{fig:hboxparallel:decomplang} defines the language of schedules.\n", "spans": [[0, 86], [87, 222], [223, 332], [333, 424]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We use a small amount of notation. Variables $p$ and $q$ denote schedules (                   ), $A$ and $B$ are sets of attributes, and $      $ and $     $ are traversal types (                        ). Attribute $a_{W, V{           }W}$ is decorated with its production ($V{           }W$) and the non-terminal within it ($W$). We write  $a_{*, V{           }W}$ if $a$ can be associated with a non-terminal on either side of the production.\n", "spans": [[0, 34], [35, 205], [206, 331], [332, 446]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The rules to check composition and individual traversals are as follows:\n", "spans": [[0, 73]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "                                                            '' and ``\\sched{||}''}The simplest composition check is for sequencing: Hoare triple ``\\sched{\\{A\\} p ; q      }'' (rule $            }$).  If attributes $A$ are solved before traversal ``\\sched{p ; q}'', then attributes $C$ will be solved after. The conditions above the judgement bar state this is true if $p$ can always compute attributes $B$ given attributes $A$, and $q$ can always then compute $C$. The judgement is recursive. Analogous reasoning explains  ``\\sched{||}'' (rule $            }$).\n", "spans": [[0, 198], [200, 306], [307, 464], [465, 492], [493, 562]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Rule $             _      }$ checks outer traversal type $      $ over regions where each one may have its own traversal type $      $. Consider an outer traversal type of  \\sched{parPre}: as it progresses top-down, every region might be guaranteed to have attributes of its root node solved before evaluation proceeds within it. For each region (the set of productions mapped to region traversal type $      $), the rule calls $                          _{               }$ to find the set $C_      $ of  attributes that are externally set before the region is traversed. Rule $             _      }$ calls checks for every region under the assumption that $C_      $ is already solved.\n", "spans": [[0, 135], [136, 329], [330, 572], [573, 688]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The first line of rule $             _      }$ means that, for any outer traversal $      $, attributes scheduled for the outer region are  treated as if they were in their own region ($       =       $). Traversals that do not use nesting are degenerate:  all the productions belong to one region ($       =       $).\n", "spans": [[0, 204], [205, 319]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The schedule for a traversal of type $     $ over a region is correct if every production visit schedule is correct (rule $              _     }$). A production visit schedule $Prod_i~             $ is correct when there is an order for computing its scheduled attributes $Step_j*$ along which all of the data dependencies of the corresponding semantic functions are satisfied. %The order exists if the transitive closure of attributes with satisfiable dependencies covers $B$. \n", "spans": [[0, 147], [148, 377], [378, 479]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Traversals that do not perform nesting, such as a single occurrence of \\sched{parPre}, are handled as degenerate nested composition with one region: the entire tree.\n", "spans": [[0, 166]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "A fast and simple checking algorithm would be to mark each attribute  of a production as dirty or clean inside a structure that persists across checks of different visits to the same production. For each successive attribute in a visit's sequence, if all of its dependencies are met (dirty), mark the attribute, and otherwise fail the check. Non-local dependencies can be handled as below.\n", "spans": [[0, 194], [195, 341], [342, 390]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "To optimize the synthesis algorithm of Chapter~\\ref{chap:4}, we use a slightly indirect algorithm to check the correctness of visiting a production.  The intuition is that it relaxes the specification of visit's attributes by treating the ordered sequence as an unordered set and checks the reachability of the set's dependency graph. \n", "spans": [[0, 148], [150, 336]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Figure~                                      shows an unoptimized reachability computation for visiting a production inside a \\sched{parPre} region. It is the standard transitive closure, except for two subtleties:\n", "spans": [[0, 148], [149, 215]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "First, only attributes that are meant to be scheduled are considered reachable ($B$ membership check in line 7). Incorrectly including unscheduled attributes would erroneously allow attributes with unresolved dependencies to also be included.  \n", "spans": [[0, 112], [113, 245]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Second, attributes computed by visits to adjacent productions must be distinguished. Adjacent productions may be in the same region or in another. In a \\sched{parPre} region, consider when $W$ is always an intermediate node of the region and attribute $a_{W,W{           }X}     B$ is always set by a parent production $V{           }W$ in the same region. For this intra-region case, $a_{W,W{           }X}$ is guaranteed to be reachable at the beginning of the visit to $W{           }X$.  However, if $W$ can be the root node of the region, we must also check $a_{W,V{           }W}$ is set by adjacent regions before the root is visited. %The checks for the intra-region case and the                            inter-region case are in lines 4-5 of $             _      }$.\n", "spans": [[0, 84], [85, 146], [147, 356], [357, 490], [492, 641], [642, 778]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Checking an explicit sequence reduces to checking that the transitive closure can be performed in the specified order rather then the declarative definition in Figure~\\ref{fig:checkers} . The synthesizer of Chapter~\\ref{chap:4} does not need to check for ordering, so we omit this check.\n", "spans": [[0, 187], [188, 288]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Property Proofs}\n", "spans": [[0, 29]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "The axioms check for determinism, which can be adapted to check the two other properties.\n", "spans": [[0, 90]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "First, the axioms check determinism, which means that rerunning the schedule will yield the same result.  We can check determinism by ensuring that a schedule computes the attributes of an attribute grammar without races. More precisely, it tracks what attributes are guaranteed to have been computed by any particular point of the schedule, and uses that to check that every step of the computation only relies on what is guaranteed to have been computed.\n", "spans": [[0, 104], [106, 221], [222, 457]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Linearity requires that that every instance of an attribute is only assigned to once. We can check linearity by extending the axioms in two ways. First, they must check that for any given attribute $X_a$, it is either defined by all productions $X             W$ or by all productions $W             X$. Second, for every attribute assigned in production $X             W$, it must only be scheduled for one visit. \n", "spans": [[0, 85], [86, 145], [146, 303], [304, 416]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Totality guarantees that every well-formed input tree yields one and only one result. It is a property of the language because any schedule must reach the same result. In contrast, determinism is a property of a schedule because, for the same language, rerunning one schedule may always return the same result while the same might not be guaranteed for another schedule. The proof of totality lies in the proof of linearity. Given a linear schedule, the dynamic dependency graph of every input document is directed and acyclic. The DAG property guarantees that the value of each node is a pure function of the values of the dominating nodes, and therefore the language has a (total) functional interpretation. Checking totality adds an additional step beyond checking linearity: totality requires that every attribute in the grammar appears in the schedule.\n", "spans": [[0, 85], [86, 167], [168, 370], [371, 424], [425, 527], [528, 709], [710, 858]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Verification is $O(|A|)$}\n", "spans": [[0, 38]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Verifying a schedule for race-freedom takes time linear in the number of attributes. Our  description of the checker in Figures~\\ref{fig:deductions} and~\\ref{fig:checkers} does not show the optimizations that lead to this bound so we highlight the key ideas here.\n", "spans": [[0, 84], [85, 264]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "First, the number of axioms to check is linear in the number of attributes. Every traversal computes at least one attribute, which implies that the number of traversals is bounded by the number of attributes. Only non-empty visits must be checked, and their number is likewise bounded by the number of attributes.\n", "spans": [[0, 75], [76, 208], [209, 314]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Second, the time to check an axiom is linearly bounded by the number of attributes (and their dependencies) to be scheduled by that axiom. For example, checking the visit to a production is effectively a topological sort of the local dependency graph restricted to the attributes evaluated during the visit. Topologically sorting dependency graph $G = (E, V)$ is $O(|E| + |V|)$. An attribute can have at most $|A|$ local dependencies so verification takes time $O(|A|)$.  For simplicity, our implementation does not use the topological sort optimization, and we only encountered performance issues on one case study due to that.\n", "spans": [[0, 138], [139, 307], [308, 378], [379, 470], [472, 629]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Similar reasoning applies to quickly checking the two other properties. Linear checking of linearity follows the same proof structure. Each attribute is labeled based on the type of production that solves it and rule $              _     }$ checks that the labels of attributes in $Step_j$ match production $Prod_i$. The time to check the axiom is therefore still bounded by the number of scheduled attributes. Finally, totality checks that the computed set of attributes matches the total set, and comparing two sets is also linear in the number of attributes.\n", "spans": [[0, 71], [72, 134], [135, 316], [317, 410], [411, 562]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\section{Evaluation: Layout as Structured Parallel Visits}\n", "spans": [[0, 59]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We show that our static language of parallel schedules is expressive enough to support common layout tasks.  In particular, we show that it can support document layout (box models and nested text), table layout (user interfaces and data tables), and rendering. Our document layout and table examples describe supporting a subset of CSS. Our rendering example highlights optimizing dynamic memory allocation for GPU. Rendering should be integrated into each layout model; we discuss how to do so at the end. The attribute grammars in Appendix~\\ref{??} include sketches~\\ref{chap:4} of the schedules described here.\n", "spans": [[0, 107], [109, 260], [261, 336], [337, 415], [416, 506], [507, 549], [549, 614]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Box model}\n", "spans": [[0, 23]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Document languages provide nested box models where intermediate nodes are boxes and leaf nodes are text and images. For example, a box may represent a page, column, or paragraph. The          example provides the basic insight, except a language such as CSS extends it with features. Of most relevance to parallelization, we describe supporting the following common features with non-trivial data dependencies~           :\n", "spans": [[0, 115], [116, 178], [179, 283], [284, 423]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      Intrinsic preferences. Document content leads to intrinsic preferences, such as as a box being big enough to contain its content. These must be combined with external constraints, such as overriding preferences set by the designer on the element or its container. \n", "spans": [[0, 28], [29, 135], [136, 271]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      Relative layout. Based on the size preferences of a node and its content, the content must be positioned relative to each other and the node.\n", "spans": [[0, 22], [23, 148]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      Absolute layout. Based on the relative positioning between a node and its parent, transitive reasoning must be applied to position the node relative to the tree's root node.\n", "spans": [[0, 22], [23, 180]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Our static box model schedule loosely corresponds to the above list by devoting 1-2 parallel passes for each item. \n", "spans": [[0, 116]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We stage the computations with the following sequence of parallel traversals:\n", "spans": [[0, 78]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Bottom-up: intrinsic widths and concrete overriding constraints.} For example, the intrinsic width of a horizontal box is the sum of intrinsic widths of its children. If the user specifies a concrete width value such as 2 pixels, that value is used instead.\n", "spans": [[0, 78], [78, 180], [181, 272]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Top-down: percent widths.}  Constraints such as a width being a percent of its parent are computed next. Notably, the CSS standard defines percent widths that cannot be computed at this point as being undefined. The definition by the CSS standard makes whatever interpretation we use safe.\n", "spans": [[0, 39], [39, 118], [119, 225], [226, 304]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Bottom-up: heights and relative positioning.} Once the size of a node's children is known, their placement relative to the node can be computed. For example, a horizontal box would place them side by side, and a vertical box would stack them. Likewise, the relative positioning of a node's children, their heights, and any overriding user constraints are sufficient for computing the node's height.\n", "spans": [[0, 58], [58, 158], [159, 256], [257, 413]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Top-down: absolute positioning.} When the absolute position of a node becomes available, the absolute positions of its children may be computed. The process proceeds recursively.\n", "spans": [[0, 45], [45, 158], [159, 193]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Nested text}\n", "spans": [[0, 25]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Our core approach to supporting nested text is described in Section~\\ref{subsec:nested}. As a reminder, the problem is to perform word-wrapping on subtrees such as paragraphs with stylized text. The idea is to identify subtrees that require sequential evaluation but can be computed in parallel with other subtrees. Given the basic insight of performing such a nesting, we use our tool to design and verify the schedule.\n", "spans": [[0, 88], [89, 194], [195, 315], [316, 421]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "A non-obvious aspect of using nested traversals for text layout  is that we only use the nesting for one pass. The computations relating to text layout span several tree traversals. The intrinsic and computed width passes execute using the parallel traversals described above. We only use the nesting for height and relative position computation. Thus, our strategy of using nested traversals achieves coarse-grained parallelism for the traversal with the difficult word-wrapping dependency, and features the usual fine-grained parallelism for all others.\n", "spans": [[0, 110], [111, 181], [182, 276], [277, 346], [347, 556]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Grids}\n", "spans": [[0, 19]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We scheduled the automatic layout algorithm used in CSS and HTML as parallel tree traversals.\n", "spans": [[0, 94]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Section~\\ref{subsec:tables} describes the functional specification. The primary dependencies challenging parallelization relate to supporting topological traversals over a DAG rather than a tree because cells have two parents: the row and the column. In a top-down traversal, both the row and column should be visited before the cell. Our solution for parallelization is a level-synchronous breadth-first evaluation order. Finally, our example propagates information between rows and columns using several intermediate parallel traversals. A nested traversal or the ability to reason about attributes of grandchildren rather than just children may help eliminate those traversals.\n", "spans": [[0, 67], [68, 250], [251, 334], [335, 422], [423, 539], [540, 681]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{SIMD Rendering through Staged Memory Allocation}\n", "spans": [[0, 61]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "We evaluate three dimensions of our staged memory allocation approach: flexibility, productivity, and performance. First, it needs to be able to express the rendering tasks that we encounter in GPU data visualization. Second, it should some form of productivity benefit for these tasks. Finally, the performance on those tasks must be fast  enough to support real-time animations and interactions of big data sets.\n", "spans": [[0, 114], [115, 217], [218, 286], [287, 415]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsubsection{Productivity}\n", "spans": [[0, 29]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Productivity is difficult to measure. Before using the automation extensions for rendering, we repeatedly encountered bugs in manipulating the allocation calls and memory buffers. The bugs related both to incorrect scheduling and to incorrect pointer arithmetic. Our new design eliminates the possibility of both bugs.\n", "spans": [[0, 37], [38, 179], [180, 262], [263, 319]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "One suggestive productivity measure is of how many lines of code the macro abstraction eliminates from our visualizations. We measured the impact on using it for 3 of our visualizations. The first visualization is our HBox language extended with rendering calls, while the other two are interactive reimplementations of popular visualizations: a treemap~[[CITE]] and multiple 3D line graphs~[[CITE]].\n", "spans": [[0, 122], [123, 186], [187, 401]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\caption{Lines of Code Before/After Invoking the '@' Macro}\n", "spans": [[0, 60]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Table~\\ref{table:macroreduction} compares the lines of code in visualizations before and after we added the macros. Using the macros eliminated 19--44 % of the code. Note that we are \\emph{not} measuring the macro-expanded code, but code that a human wrote.\n", "spans": [[0, 115], [116, 165], [166, 258]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "As shown in Figure~\\ref{fig:stagedallocClient}, the eliminated code is code that was introduced by staging the library calls. Porting unstaged functional graphics calls to the library, is in practice, an alpha renaming of function names.  Using the '@' macro eliminates 19--44 % of the code that would have otherwise been introduced and completely eliminates two classes of bugs (scheduling and pointer arithmetic), so the productivity benefit is non-trivial. \n", "spans": [[0, 125], [126, 237], [239, 461]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsubsection{Performance}\n", "spans": [[0, 28]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\subsection{Discussion}\n", "spans": [[0, 24]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "An interesting distinction arises between our use of attribute grammars and our approach of parallel traversals. The restricted attribute grammars prevents specifying computations that could be manually expressed with the tree traversals. Thus, we found that our box model can be manually encoded with 3-5 parallel traversals, but expressing it with our restricted attribute grammar formalism may require additional parallel traversals. An important future direction would therefore be to increase the flexibility and reasoning over the attribute grammar while maintaining the set of parallel traversal types.\n", "spans": [[0, 112], [113, 238], [239, 436], [437, 610]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "\\section{Related Work}\n", "spans": [[0, 23]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Lang of schedules\n", "spans": [[0, 18]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      background\n", "spans": [[0, 17]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      stencils and skeletons: wavefront, ...\n", "spans": [[0, 45]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      polyhedra\n", "spans": [[0, 16]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Schedule verification\n", "spans": [[0, 22]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "      compare to OAG etc., looser dataflow/functional langs\n", "spans": [[0, 60]], "file": "../../thesis/template/chap3.tex"}
,
{"errors": [], "paragraph": "Programmers struggle to map applications into parallel algorithms. Going beyond the automatic schedule verification of the last chapter, we now examine how to automatically generate a schedule.  Consider two of the decisions that a programmer faces in manually designing a schedule:\n", "spans": [[0, 66], [67, 193], [195, 283]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Scheduling a single traversal.} Many computations contain sequential dependencies between nodes. One correct traversal over the full tree might then be sequential. However, if the sequential dependencies can be isolated to a subtree, an overall parallel traversal would be possible if it invokes a sequential traversal for just the isolated subtree. Whether such isolation is always possible is not obvious.\n", "spans": [[0, 44], [44, 110], [111, 177], [178, 363], [364, 422]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Scheduling multiple traversals.} Programs such as browsers perform many traversals. Traversals might run one after another, concurrently, or be fused into one. These choices optimize for different aspects of the computation. Running two traversals in parallel improves scaling, but fusing them into one parallel traversal avoids overheads: the choice may depend on both the hardware and tree size. Which traversal sequence to use is not obvious.\n", "spans": [[0, 45], [45, 97], [98, 173], [174, 238], [239, 411], [412, 460]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "These decisions explode the space of schedules. Today, programmers manually navigate the space by selecting a parallel schedule, judging its correctness,  and comparing its efficiency to alternative schedules. The tasks are expensive: programmers  globally reason about dependencies, develop prototypes for profiling, and whenever the functional specification changes, restart the process. \n", "spans": [[0, 47], [48, 209], [210, 391]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "This chapter explores the design and implementation of an attribute grammar that supports automatic schedule synthesis.\n", "spans": [[0, 120]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "We examine several questions: \n", "spans": [[0, 31]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      What programming constructs are enabled by schedule synthesis?\n", "spans": [[0, 69]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      What is an algorithm to \\emph{quickly} find a \\emph{correct} schedule?\n", "spans": [[0, 77]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      If multiple schedules are possible, how do we find a \\emph{fast} one?\n", "spans": [[0, 76]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "The following sections explore each question in turn. \n", "spans": [[0, 55]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\section{Computer-Aided Programming with Schedule Sketching}\n", "spans": [[0, 61]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "Automatic parallel schedule synthesis enables rich forms of parallel programming. The utility of these constructs is not obvious. An automation tool will automatically find a parallel schedule, so a natural conclusion would be to assume the programming interface simply hide all parallelization concerns and rely upon automatic parallelization internally. We found this to be largely true for writing small amounts of declarative data visualization code. However, in parallelizing the larger and more complicated CSS layout language, we encountered cases where the visualization designer needed to guide (or be guided by) the automation procedure. Likewise, we encountered the need for one programmer to communicate parallel structure to another. Automatic parallelization is insufficient in that it hides all parallelization details and controls, yet manual scheduling was too low-level and brittle.\n", "spans": [[0, 81], [82, 129], [130, 355], [356, 454], [455, 647], [648, 746], [747, 901]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "Our solution is to provide a \\emph{sketching} construct for specifying constraints on the schedule that the automatic parallelization algorithm must respect. The programmer chooses which parts of a schedule to write and relies upon the synthesizer to fill in the rest. We routinely sketched schedules in order to \\emph{override schedule selection}, \\emph{test} and \\emph{debug} parallelization ideas, and \\emph{enforceably communicate parallelization decisions} when sharing code with others. Discussed later in this chapter~\\ref{??}, we also used the sketching mechanism to speed up automatic parallelization over specifications with many attributes or schedule patterns that challenge static analysis.\n", "spans": [[0, 157], [158, 268], [269, 492], [493, 532], [532, 704]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "We revisit the specification of          to demonstrate the sketching construct and its use for the above scenarios. First, depending on the expected memory size of target hardware, the programmer may choose a longer schedule with a smaller set of attributes computed in each one. Compare the three following schedule sketches:\n", "spans": [[0, 116], [117, 280], [281, 328]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Trace of synthesizing schedules for \\hlang{}}. Note that scheduling of ``$||$'' does not use the optional greedy heuristic.}\n", "spans": [[0, 63], [64, 140], [140, 142]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "Synthesizing one schedule is $O(A^3)$ in the number of attributes. The algorithm finds an increasingly long and correct prefix of the schedule (\\emph{prefix expansion}). At each step, it tries different suffixes until one succeeds, where a suffix such as ``\\sched{parPre\\{x,y\\}}'' is a traversal type and attributes to compute in it. When a correct suffix is found, it is appended to the prefix and the loop continues on to the next suffix. Finding one suffix involves trying different traversal types, and for each one, different attributes. Only the suffix needs to be checked (\\emph{incremental checking}), and checking a suffix is fast (\\emph{topological sort}). Finally, finding a set of attributes computable by a particular traversal type only requires $O(A)$ attempts (\\emph{iterative refinement}).\n", "spans": [[0, 66], [67, 169], [170, 333], [334, 440], [441, 542], [543, 666], [667, 807]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "We consider each optimization in turn:\n", "spans": [[0, 39]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Prefix expansion.} The synthesizer searches for an increasingly large \\emph{correct} schedule prefix. Every line of the trace represents a prefix. If a prefix is incorrect, no suffix will yield a correct schedule. Therefore, the only prefixes that get expanded are those that succeed (lines 2, 4, 7, 10, 15, 18). \n", "spans": [[0, 31], [31, 115], [116, 160], [161, 227], [228, 328]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "To synthesize only one schedule, only one increasingly large prefix is expanded. Line 2 has a correct prefix, so only ``\\sched{parPre\\{y\\}}'' would be explored. Either no schedule is possible at all, or if there are any, one is guaranteed to exist in the expansion. In this case,  ``\\sched{parPre\\{y\\} ; parPost        ; parPre     }'' would be found.\n", "spans": [[0, 80], [81, 160], [161, 265], [266, 352]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Incremental checking.} Line 4  checks prefix ``\\sched{parPost\\{w,h\\}}'' for attributes ``w'' and ``h.'' Therefore, lines 5-17 can check the suffix added at each line without rechecking  ``\\sched{parPost\\{w,h\\}}''. \n", "spans": [[0, 35], [35, 115], [115, 229]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Topological sort.} We optimize checking a suffix by topologically sorting the dependency graph of its attributes  (rule $                   $ in the next subsection). Topologically sorting a graph is $O(V + E)$.  It is $O(A)$ in this case because $V = A$, and as the arity of semantic functions is generally small, $E$ is $O(A)$.  \n", "spans": [[0, 31], [31, 180], [181, 225], [227, 346]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Iterative refinement.} The algorithm iteratively refines an over-approximation of what attributes can be computed in a suffix by removing under-approximations of what cannot. For example, the check in line 1 for \\sched{parPre\\{x,y,w,h\\}} fails with error           |{x,w,h}|, which details the attributes with unsatisfiable dependencies. Computing fewer attributes cannot satisfy more dependencies, so no  subset of           |{x,w,h}| has satisfiable dependencies either. Therefore, the next check is on a set without them:           |{y}|. \n", "spans": [[0, 35], [35, 188], [189, 351], [352, 486], [487, 557]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "Subtraction of attributes repeats at most $A$ times before finding a solution or terminating on the empty set. Checking one refinement invokes the $O(A)$ topological sort. Put together, finding the attributes computable by a suffix is $O(A^2)$.\n", "spans": [[0, 110], [111, 171], [172, 245]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "          Every traversal computes at least one attribute, so there are at most $A$ traversals. A constant number of traversal types are examined for each suffix, and synthesizing each one is $O(A^2)$. Synthesizing one schedule is therefore $O(A^3)$.  The \\emph{greedy sketch unification} optimization from the next section may further optimize the synthesis of a single schedule.\n", "spans": [[0, 95], [96, 201], [202, 250], [252, 381]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\section{Schedule Enumeration}\n", "spans": [[0, 31]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "We provide and optimize the ability to examine many schedules. Our approach benefits several scenarios: picking a fast schedule when many are possible, supporting scheduling language extensions that otherwise resist fast synthesis, and improving synthesis time when partial schedule knowledge is known.\n", "spans": [[0, 62], [63, 303]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "We consider each scenario in turn:\n", "spans": [[0, 35]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\textbf{Autotuning} There may be an exponential number of schedules, and the choice of the fast is non-obvious. For example, shorter schedules incur less traversal overhead, but also generally expose less parallelism. Likewise, a short sequence of parallel traversals may behave worse than a long sequence when performed on hardware with limited memory. By enumerating all schedules, we can perform \\emph{autotuning}: run performance tests to pick the best schedule for a particular architecture. There may be an exponential number of schedules, so we must somehow optimize the enumeration of those to test.\n", "spans": [[0, 111], [112, 217], [218, 353], [354, 496], [497, 608]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": " \\textbf{Scheduling extensions.} We provide optional scheduling language extensions, and fast synthesis in their presence requires optimization. For example, nested traversals require partitioning the set of nodes into distinct regions, but many partitions are possible. Partitioning does not enjoy the monotonicity property that we previously exploited and thus, on its own, is slow.\n", "spans": [[0, 31], [31, 144], [145, 270], [271, 385]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": " \\textbf{Faster synthesis.} Verification is linear-time in theory yet running the synthesizer to perform it, as is, takes cubic time.  If the programmer provides knowledge of the schedule, such as when recompiling the grammar, synthesis should execute faster. In the limit, providing full schedule knowledge should reduce synthesis time to that of verification.\n", "spans": [[0, 26], [26, 133], [135, 259], [260, 362]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "We introduce several optimizations that, together, address the above scenarios. They optimize for when multiple schedules may be valid schedules, and except for backtracking, may also improve the process of finding one schedule. \n", "spans": [[0, 79], [80, 230]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Backtracking.} To emit multiple schedules, we extend prefix expansion to also perform backtracking. After a schedule is fully completed or a suffix fails, the synthesizer backtracks to the most recent correct prefix. For example, line 8 is a complete and correct schedule. Backtracking returns to the earlier correct prefix of line 7 and tries the alternative suffix of line 9. \n", "spans": [[0, 27], [27, 113], [114, 230], [231, 286], [287, 393]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Greedy sketch unification.} We use sketches to prune the search. For example,  sketch\n", "spans": [[0, 40], [40, 78], [79, 100]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "enables skipping lines 1-3 because they do not start with a \\sched{parPost} traversal. Lines 5-13 could also be skipped because the compositor is not ``$||$''. \n", "spans": [[0, 86], [87, 161]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "A sketch that provides a full schedule reduces synthesis to verification, which is $O(A)$ (topological sort). Sketching also enable features that otherwise require exponential search to still synthesize in $O(A^3)$. For example, scheduling nested regions is exponential in the number productions, but if just the production partitioning is sketched, synthesis for the remaining schedule terms is still only $O(A^3)$.\n", "spans": [[0, 109], [110, 215], [216, 417]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Greedy attribute heuristic.} For any schedule ``\\sched{p ; q}'', solving fewer attributes in $p$ will not enable solving $q$ with fewer traversals. Thus, to minimize the number of traversals, all such subsets are pruned. For example, as line 4 found \\sched{parPost\\{w,h\\}}, line 19 skips ``                                  |parPost{w} ; _ |'' and proceeds to ``\\sched{parPost\\{w\\} || _}''. \n", "spans": [[0, 41], [41, 161], [162, 234], [235, 406]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "Greediness reduces enumerating all schedules to only being exponential in the number of traversals. This is significant because, for example, our schedule for CSS has only 9 traversals.\n", "spans": [[0, 99], [100, 186]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "In summary, synthesizing one schedule in our base language is $O(A^3)$, but emitting all of them is exponential. Likewise, scheduling language extensions such as nested traversals still support fast synthesis of surrounding terms when guided by sketches. Our optimizations optimize the process, such as by reducing synthesis complexity to that of verification when increasingly detailed sketches are provided.\n", "spans": [[0, 112], [113, 254], [255, 410]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Optimized synthesis algorithm.} Lines 10,15,18: early unification with sketches. Lines 8,27: incremental checking. Line 26: iterative  refinement. Line 31: toggle minimal length schedules. Lines 12,28: pruning of traversals with unsatisfiable dependencies. }\n", "spans": [[0, 47], [47, 97], [98, 131], [132, 163], [164, 205], [206, 273], [274, 276]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\section{Evaluation}\n", "spans": [[0, 21]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "We evaluate our schedule synthesizer in several ways. First, we examine the ability to automatically parallelize grammars: which computations we entirely relied upon automatic parallelization and the complexity of sketches written for the rest. Second, we evaluate the speed of our synthesis algorithm on our case studies with a focus on supporting interactive compile times. Finally, we examine schedule quality: we measure the benefit of autotuning and the cost of our greedy heuristic.\n", "spans": [[0, 53], [54, 244], [245, 375], [376, 489]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\subsection{Case Studies: Sketching in Action}\n", "spans": [[0, 47]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "Show use in CSS and data viz: \n", "spans": [[0, 31]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      when automatic is fine\n", "spans": [[0, 29]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      when sketch needed for checking/debugging\n", "spans": [[0, 48]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "      when sketch needed for sharing\n", "spans": [[0, 37]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\subsection{Speed of synthesis}\n", "spans": [[0, 32]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "Success, fail, enumerate\n", "spans": [[0, 25]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\subsection{Line counts of extensions}\n", "spans": [[0, 39]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\subsection{Loss from greedy heuristic}\n", "spans": [[0, 40]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\subsection{Benefit from autotuning}\n", "spans": [[0, 37]], "file": "../../thesis/template/chap5.tex"}
,
{"errors": [], "paragraph": "\\section{Overview}\n", "spans": [[0, 19]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "For a full language, statically identified parallelization opportunities still require an efficient runtime implementation that exploits them. In this section, we show how to exploit the logical concurrency identified within a tree traversal to optimize for the architectural properties of two types of hardware platforms: MIMD (e.g., multicore) and SIMD (e.g., sub-word SIMD and GPU) hardware. For both types of platforms, we optimize the schedule within a traversal and the data representation. We innovate upon known techniques in two ways:\n", "spans": [[0, 142], [143, 394], [395, 496], [497, 544]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Semi-static work stealing for MIMD:} MIMD traversals should be optimized for low overheads, load balancing, and locality. Existing techniques such as work stealing provide spatial locality and, with tiling, low overheads. However, dynamic load balancing within a traversal leads to poor temporal locality across traversals. The processor a node is assigned to in one traversal may not be the same one in a subsequent traversal, and as the number of processors increases, the probability of assigning to a different one increases. Our solution dynamically load balances one traversal and, due to similarities across traversals, successfully reuses it.\n", "spans": [[0, 135], [136, 235], [236, 337], [338, 543], [544, 665]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Clustering traversals for SIMD:}  SIMD evaluation is sensitive to divergence across parallel tasks in instruction selection. Visits to different types of tree nodes yield different instruction streams, so na     e vectorization fails for webpages due to their visual variety. Our insight is that similar nodes can be semi-statically identified. Thus \\emph{clustered} nodes will be grouped in the data representation and run in SIMD at runtime.\n", "spans": [[0, 138], [139, 289], [290, 358], [359, 458]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Our techniques are important and general. They overcame bottlenecks preventing seeing any speedup from parallel evaluation for webpage layout and data visualization. Notably, they are generic to computations over trees, not just layout. An important question going forward is how to combine them as, in principle, they are complementary.\n", "spans": [[0, 41], [42, 165], [166, 236], [237, 338]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\section{MIMD: Semi-static work stealing}\n", "spans": [[0, 42]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\section{SIMD Background: Level-Synchronous Breadth-First Tree Traversal}\n", "spans": [[0, 74]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "The common baseline for our two SIMD optimizations is to implement parallel preorder and postorder tree traversals as level-synchronous breadth-first parallel tree traversals. Reps first suggested such an approach to parallel attribute grammar evaluation [[CITE]], but did not implement it. Performance bottlenecks led to us deviate from the core representation used by more recent data parallel languages such as NESL [[CITE]] and Data Parallel Haskell [[CITE]]. We discuss our two innovations in the next subsections, but first overview the baseline technique established by existing work.\n", "spans": [[0, 175], [176, 290], [291, 463], [464, 592]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{SIMD tree traversal as level-synchronous breadth-first iteration with corresponding structure-split data representation.}}\n", "spans": [[0, 137], [137, 140]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "The na     e tree traversal schedule is to sequentially iterate one level of the tree at a time and  traverse the nodes of a level in parallel. A parallel preorder traversal starts on the root node's level and then proceeds downwards, while a postorder traversal starts on the tree fringe and moves upwards (Figure~\\ref{fig:bfstraversal}~\\ref{fig:bfstraversal:code}). Our MIMD implementation, in contrast, allows one processor to compute on a different tree level than another active processor. In data visualizations, we empirically observed that most of the nodes on a level will dispatch to the same layout instructions, so our na     e traversal schedule avoids instruction divergence.\n", "spans": [[0, 143], [144, 367], [368, 494], [495, 690]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "The level-synchronous traversal pattern eliminates many divergent memory accesses by using a corresponding data representation. Adjacent nodes in the schedule are collocated in in memory. Furthermore, individual node attributes are stored in \\emph{column} order through a array-of-structure to structure-of-array conversion. The conversion collocates individual attributes, such as the width attribute of one node being stored next to the width attribute of the node's sibling (Figure~\\ref{fig:bfstraversal:repmem}). The index of a node in a breadth-first traversal of the tree is used to perform a lookup in any of the attribute arrays. The benefit this encoding is that, during SIMD  layout of several adjacent nodes, reads and writes are coalesced into  bulk reads and writes. For example, if a layout pass adds a node's padding to its width, several contiguous paddings and several contiguous widths will be read, and the sum will be stored with a contiguous write. Such optimizations are crucial because the penalty of non-coalesced access is high and, for layout, relatively few computations occur between the reads and writes.\n", "spans": [[0, 127], [128, 187], [188, 324], [325, 516], [517, 637], [638, 779], [780, 969], [970, 1134]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Full implementation of the data representation poses several subtleties. \n", "spans": [[0, 74]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Level representation.} To eliminate traversal overhead, a summary provides the index of the first and last node on each level of a tree. Such a summary provides  data range information for launching the parallel kernels that evaluate the nodes of a level as well as the information for how to proceed to the next level.\n", "spans": [[0, 35], [35, 150], [151, 334]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Edge representation.} A node may need multiple named lists of children, such as an HTML table with a header, footer, and an arbitrary number of rows. We encode the table's edges as 3 global arrays of offsets: header, footer, and first-row. To support iterating across rows, we also introduce a 4th array to encode whether a node is the last sibling. Thus, any named edge introduces a global array for the offset of the pointed-to node, and for iteration, a shared global array reporting whether a node at a particular index is the end of a list.\n", "spans": [[0, 34], [34, 163], [164, 253], [254, 363], [364, 560]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Memory compression.} Allocating an array the size of the tree for every type of node attribute wastes memory. We instead statically compute the maximum number of attributes required for any type of node, allocate an array for each one, and map the attributes of different types of nodes into different arrays. For example, in a language of HBox nodes as Circle nodes who have attributes 'r' and 'angle', 4 arrays will be allocated. The HBox requires an array for each of the attributes 'w', 'h', 'x', and 'y' while the Circle nodes only require two arrays. Each node has one type, and if that that type is HBox, the node's entry in the first array will contain the 'w' attribute. If the node has type Circle, the node's entry in the first entry will contain the 'r' attribute.\n", "spans": [[0, 33], [33, 123], [124, 323], [324, 445], [446, 570], [571, 693], [694, 791]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Tiling.} Local structural mutations to a tree such as adding or removing nodes should not force global modifications. As most SIMD hardware has limited vector lengths (e.g., 32 elements wide), we split our representation into blocks. Adding nodes may require allocation of a new block and reorganization of the old and new block. Likewise, after successive additions or deletions, the overall structure may need to be compacted. Such techniques are standard for file systems, garbage collectors, and databases.\n", "spans": [[0, 21], [21, 131], [132, 247], [248, 343], [344, 442], [443, 525]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "In summary, our basic SIMD tree traversal schedule and data representation descend from the approach of NESL [[CITE]] and Data Parallel Haskell [[CITE]]. Previous work shows how to generically convert a tree of structures into a structure of arrays. Those approaches do not support statically unbounded nesting depth (i.e., tree depth), but our system supports arbitrary tree depth because our transformation is not as generic.  \n", "spans": [[0, 153], [154, 249], [250, 430]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "A key property of all of our systems, however, is that the structure of the tree is fixed prior to the traversals.  In contrast, for example, parallel breadth-first traversals of graphs will dynamically find a minimum spanning tree [[CITE]]. Such dynamic alternatives incur unnecessary overheads when performing a sequence of traversals and sacrifice memory coalescing opportunities. Layout is often a repetitive process, whether due to multiple tree traversals for one invocation or an animation incurring multiple invocations, so costs in creating an optimized data representation and schedule are worth paying.\n", "spans": [[0, 114], [116, 241], [242, 383], [384, 614]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\section{Input-dependent Clustering for SIMD Evaluation}\n", "spans": [[0, 57]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\section{Evaluation}\n", "spans": [[0, 21]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Speedups and strong scaling across different backends (Back) and hardware}. Baseline is a sequential traversal with no data layout optimizations. FTL is our multicore tree traversal library. Left columns show total speedup (including data layout optimizations by our code generator) and right columns show just parallel speedup. Server = Opteron 2356, laptop = Intel Core i7, mobile = Atom 330.}\n", "spans": [[0, 92], [93, 162], [163, 207], [208, 345], [346, 411], [411, 413]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\subsection{MIMD Data Representation and Scheduling Optimizations}\n", "spans": [[0, 67]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "By statically exposing traversal structure (e.g., \\sched{parPre}) to our code generators, we observe sequential and parallel speedups. We separately evaluate the importance of the data representation optimizations from the scheduling ones on random 500-1000 node documents in the            language. Finally, we examine the parallel benefit on webpages.\n", "spans": [[0, 134], [135, 300], [301, 355]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "We first evaluate the perform of our task scheduler (FTL in Table~\\ref{tab:diffhw}).  Our comparison point is Intel's TBB~                dynamic task scheduler that performs work stealing~           , which was the most efficient third-party work stealing library that we tried. We included our data layout optimizations in all calculations because, without them, we saw no speedup.  TBB causes slowdowns until achieving no cost (nor benefit) at 8 cores. Our insight is that it suffered from high overheads: switching to scheduling tiles by using our optimized data representation improved performance. Our semi-static working stealing scheduler, however, achieved a 6.9X speedup on 8 cores. We did not see significant further speedups for higher core counts, and hypothesize that it is due to the socket jump. We experimented with other schedulers, such as a simple for-loop over tiles near the fringe of the tree, but the achieved 2X speedup is much lower than the 6.9X of our semi-static work stealer.\n", "spans": [[0, 84], [86, 279], [280, 383], [385, 455], [456, 603], [604, 692], [693, 811], [812, 1006]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Data representation was key to achieving parallel speedups. It achieved 1.2X-1.4X speedups for sequential processing (Table~\\ref{tab:diffhw}). However, on 4 cores, it improved performance from 2.8X without data representation optimizations to 5.2X when using them. The difference is 1.9X: our data representation optimizations both complement and improve scheduling optimizations. Without them, parallel performance was poor.\n", "spans": [[0, 59], [60, 142], [143, 264], [265, 380], [381, 426]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Parallel CSS layout engine}. Run on a 2356 Opteron.}\n", "spans": [[0, 45], [46, 68], [68, 70]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Table~\\ref{fig:cssperf} shows the parallel speedup on running our 9 pass layout engine for two popular web pages that render faithfully with it: Wikipedia and the XKCD blog. Note that the benchmarks do \\emph{not} include sequential speedups. The best performance of TBB was a 1.8X speedup on 4 cores, and its speedup on 8 cores was 1.2X. In comparison, our scheduler achieved 2.8X on 2 cores and 3.2X on 8X. Our insight as to why we did not see further benefits is overheads. Across our benchmarks, we generally saw speedups when sequential traversals took longer than a certain amount, but because so many traversals are used for CSS, enough of them are small enough that we do not expect strong scaling. Our intuition is that either a full layout engine is complicated enough that the sequential cost of each traversal will be higher than in our prototype, or even more aggressive data representation optimizations should be performed. As is, we have demonstrated significant 3X+ speedups on real workloads from just the parallelization.\n", "spans": [[0, 173], [174, 241], [242, 337], [338, 407], [408, 475], [476, 705], [706, 937], [938, 1040]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Sequential and Parallel Benefits of Breadth-First Layout and Staged Allocation.} Allocation is merged into the 4th stage and buffer indexing and tessellation form the rendering pass. JavaScript variants use HTML5 canvas drawing primitives while WebCL does not include WebGL painting time ($<$ 5ms). Thin vertical bars indicate standard deviation and horizontal bars show deadlines for animation and hand-eye interaction.}\n", "spans": [[0, 96], [96, 199], [200, 315], [316, 437], [437, 439]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\subsection{Baseline SIMD Speedups (GPU)}\n", "spans": [[0, 42]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "We evaluate the sequential and parallel performance benefits of our baseline breadth-first layout.   For an animation to achieve 24fps, the time spent to process a frame should not exceed 42ms, and for eye-hand interactions, 100ms (10fps). We examine the case of a 5 pass treemap that supports live filtering over 100,000 data points. The first 3 passes are purely devoted to layout, the 4th pass includes layout computations and allocation requests, and the 5th pass propagates buffer indices and performs tessellation. \n", "spans": [[0, 98], [101, 239], [240, 334], [335, 522]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "We compare 3 backends for our compiler: canonical JavaScript (a tree of nodes), JavaScript over our structure-split breadth-first tree layout (and with typed arrays~[[CITE]]), and WebCL for the GPU.  The first two variants invoke HTML5 canvas drawing primitives, while the last invokes WebGL (GPU) painting primitives over vertex buffers computed in the rendering pass. The time for WebGL painting calls are not shown, but they take less than 5ms. Each variant is repeated 15 times on a 4 core 2012 2.66GHz Intel Core i7 with 8 GB memory and a 1024 MB NVIDIA GeForce GT 650M graphics card.\n", "spans": [[0, 198], [200, 369], [370, 447], [448, 590]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "We first examine  the significant sequential benefits.The first 4 groups of columns in Figure~\\ref{fig:treemapjsgpu} shows the average time spent on different layout passes and the 6th on the pass for buffer index computation and tessellation. Performing compiler optimizations enables a 14X sequential speedup on layout in the Chrome web browser. No speedup is observed in the rendering pass because the time is dominated by HTML5 canvas calls. We hypothesize part of the sequential benefit is related to our clustering optimization: all of the nodes in a level have the same type, so implicit optimizations such as branch prediction should perform better. Finally, we note that while sequential layout time is a magnitude too slow for real-time animation, our prototype is within 54ms for real-time interaction (ignoring rendering).\n", "spans": [[0, 243], [244, 347], [348, 445], [446, 657], [658, 835]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Parallel speedups are also significant. WebCL (GPU) evaluation of layout is 5X faster than sequential. The impact of compiling JavaScript vs. C (WebCL) on the benchmark is unclear: JavaScript is generally a magnitude slower than native code, except the runtime WebCL compiler is not running at high optimization levels. The benefits for parallel computation of the buffer indices and tessellation is much more clear: the speedup is 31X. \n", "spans": [[0, 39], [40, 102], [103, 141], [142, 319], [320, 438]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Multicore vs. GPU Acceleration of Layout.} Benchmark on an early version of the treemap visualization and does not include rendering pass.}\n", "spans": [[0, 30], [31, 58], [58, 155], [155, 157]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "To better understand the benefit of parallelization, we compared running the layout traversals using multicore vs. GPU acceleration (Figure~\\ref{fig:cpuvsgpu}) for an early prototype of the layout traversals. Both use breadth-first traversals compiled with OpenCL, except differ on the hardware target. We see that a server-grade multiprocessor (32-core AMD Opteron 2356) can outperform a laptop GPU, but the comparison is unfair in terms of power consumption. TODO compare power ratings.\n", "spans": [[0, 114], [115, 208], [209, 302], [303, 460], [461, 489]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Ultimately, when the sequential and parallel optimizations are combined, we see an end-to-end speedup of 54X. It is high enough such that it enables real-time animation for our data set, not just real-time user interaction.\n", "spans": [[0, 109], [110, 224]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\subsection{SIMD Clustering}\n", "spans": [[0, 29]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "We evaluate several aspects of our clustering approach. First, we examine applicability to various visualizations. Second, we evaluate the speed and performance benefit. Clustering provides invariants that benefit more than just vectorization, so we distinguish sequential vs. parallel speedups. Finally, there are different options in what clusters to form, so for each stage of evaluation, we compare impact.\n", "spans": [[0, 55], [56, 114], [115, 169], [170, 276], [277, 295], [296, 411]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Compression ratio for different CSS clusterings.} Bars depict compression ratio (number of clusters over number of nodes). Recursive clustering is for the reduce pattern, level-only for the map pattern. ID is an identifier set by the C3 browser for nodes sharing the same style parse information while value is by clustering on actual style field values.}\n", "spans": [[0, 65], [65, 139], [140, 219], [220, 371], [371, 373]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\subsubsection{Applicability}\n", "spans": [[0, 30]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "We examined idealized speedup for several workloads:\n", "spans": [[0, 53]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Synthetic.} For a controlled synthetic benchmark, we simulated the effect of increasing number of clusters on speedup for various SIMD architectures.  Our simulation assumes perfect speedups for SIMD evaluation of nodes run together on a SIMD unit. The ideal speedup is a function of the minimum of the SIMD unit's length (for longer clusters, multiple SIMD invocations are mandatory) and the number of clusters (at least one SIMD step is necessary for each cluster).   Figure~\\ref{fig:simulatedclusteringspeedup} shows, for architectures of different vector length, that the simulated speedup from clustering (solid black line with circles) is close to the ideal speedup (solid green line).\n", "spans": [[0, 24], [24, 163], [165, 262], [263, 481], [484, 706]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      \\textbf{Data visualization.} For our data visualizations, we found that, across the board, all of the nodes of a level shared the same type. For example, our visualization for multiple line graphs puts the root node on the first level, the axis for each line graph on the second level, and all of the actual line segments on the third level. \n", "spans": [[0, 33], [33, 146], [147, 349]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      \\textbf{CSS.} We analyzed potential speedup on webpages. Webpages are a challenging case because an individual webpage features high visual diversity, with popular sites using an average of 27KB of style data per page.~                                                                   . We picked 10 popular websites from the Alexa Top 100 US websites that rendered sufficiently correctly in the C3~[[CITE]] web browser. It was also challenging in practice because it required clustering based on individual node attributes, not just the node type.\n", "spans": [[0, 18], [18, 62], [63, 293], [294, 427], [428, 556]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Figure~{fig:csscompression} compares how well nodes of a webpage can be clustered. It reports the \\emph{compression ratio}, which divides the number of clusters by the number of nodes. Sequential execution would assign each node to its own cluster, so the ratio would be 1. In contrast, if the tree is actually a list of 100 elements, and the list can be split into 25 clusters, the ratio would be 25 %. Assuming infinite-length vector processors and constant-time evaluation of a node, the compression ratio is the exact inverse of the speedup. A ratio of 1 leads to a 1X speedup, and a compression ratio of 25 % leads to a 4X speedup.\n", "spans": [[0, 82], [83, 184], [185, 273], [274, 403], [404, 545], [546, 637]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Clustering each level by attributes that influence control flow achieved a 12 % compression ratio (Figure~{fig:csscompression}): an 8.3X idealized speedup. When we strengthened the clustering condition to enforce stronger invariants in the cluster, such as to consider properties of the parent node, the ratio quickly worsened. Thus, we see that our basic approach is promising for websites on modern subword-SIMD instruction sets, such as a 4-wide SSE (x86) and NEON (ARM), and the more recent 8-wide AVX (x86). Even longer vector lengths are still beneficial because some clusters were long. However, eliminating all divergences requires addressing control flows influenced by attributes of node neighbors, which leads to poor compression ratios. Thus, we emphasize that 8.3X is an upper bound on the idealized speedup: not all branches in a cluster are addressed.\n", "spans": [[0, 155], [156, 327], [328, 512], [513, 593], [594, 748], [749, 867]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Empirically, we see that clustering is applicable to CSS, and in the case of our data visualizations, unnecessary. Vectorization limit studies based on analyzing dynamic data dependencies from program traces suggest that general programs can be much more aggressively vectorized, so clustering may be the beginning of one such approach~[[CITE]].\n", "spans": [[0, 114], [115, 346]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "B =breadth first, S = structure splitting, M = level clustering, R = nested clustering, H = hoisting, V = SSE 4.2 \n", "spans": [[0, 115]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Speedups from clustering on webpage layout.} Run on a 2.66GHz Intel Core i7 (GCC 4.5.3 with flags -O3 -combine -msse4.2) and does not preprocessing time.\n", "spans": [[0, 60], [60, 171]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\subsubsection{Speedup}\n", "spans": [[0, 24]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "We evaluate the speedup benefits of clustering for webpage layout. We take care to distinguish sequential benefits from parallel, and of different clustering approaches. Our implementation was manual:  we examine optimizing one pass of the C3~[[CITE]] browser's CSS layout engine that is responsible for computing intrinsic dimensions. The C3 browser was written in C #, so we wrote our optimized traversal in C + + and pinned the memory for shared access.  We use a breadth-first tree representation and schedule for our baseline, but note that doing such a layout already provides a speedup over C3's unoptimized global layout. \n", "spans": [[0, 66], [67, 169], [170, 335], [336, 456], [458, 631]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "For our experimental setup, we evaluate the same popular webpages above that rendered legibly with the experimental C3 browser.  Benchmarks ran on a 2.66GHz Intel Core i7 (GCC 4.5.3 with flags -O3 -combine -msse4.2). We performed 1,000 trials, and to avoid warm data cache effects, iterated through different webpages.\n", "spans": [[0, 127], [129, 216], [217, 319]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "We first examine sequential performance. Converting an array-of-structures to a structure-of-arrays causes a 10 % slowdown (B S in Figure~\\ref{fig:cssspeedup}). However, clustering each level and hoisting computations shared throughout a cluster led to a 2.1X sequential benefit (M S H). Nested clustering provided more optimization opportunities, but the compression ratio worsened: it only achieved a 1.7X sequential speedup (R S H). Clustering provides a significant sequential speedup.\n", "spans": [[0, 40], [41, 160], [161, 287], [288, 435], [436, 490]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Next, we examine the benefit of vectorization. SSE instructions provide 4-way SIMD parallelism. Vectorizing the nested clustering improves the speedup from 1.7X to 2.6X, and the level clustering from 2.1X to 3.5X. Thus, we see significant total speedups. The 1.7X relative speedup of vectorization, however, is still far from the 4X: level clustering suffers from randomly strided children, and the solution of nested clustering sacrifices the compression ratio.\n", "spans": [[0, 46], [47, 95], [96, 213], [214, 254], [255, 463]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Performance/Watt increase for clustered webpage layout.}}\n", "spans": [[0, 72], [72, 75]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\subsubsection{Power}\n", "spans": [[0, 22]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Much of our motivation for parallelization is better performance-per-Watt, so we evaluate power efficiency. To measure power, we sampled the power performance counters during layout. Each measurement looped over the same webpage over 1s due to the low resolution of the counter. Our setup introduces warm cache effects, but we argue it is still reasonable because a full layout engine would use multiple passes and therefore also have a warm cache across traversals.\n", "spans": [[0, 107], [108, 182], [183, 278], [279, 467]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "In Figure~\\ref{fig:csspower}, we show a 2.1X improvement in power efficiency for clustered sequential evaluation, which matches the 2.1X sequential speedup of Figure~\\ref{fig:cssspeedup}. Likewise, we report a 3.6X cumulative improvement in power efficiency when vectorization is included, which is close to the 3.5X speedup. Thus, both in sequential and parallel contexts, clustering improves performance per Watt. Furthermore, it supports the general reasoning in parallel computing of 'race-to-halt' as a strategy for improving power efficiency.\n", "spans": [[0, 187], [188, 325], [326, 415], [416, 549]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\caption{\\textbf{Impact of data relayout time on total CSS speedup.} Bars depict layout pass times. Speedup lines show the impact of including clustering preprocessing time.}\n", "spans": [[0, 67], [67, 99], [100, 173], [173, 175]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\subsubsection{Overhead}\n", "spans": [[0, 25]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "Our final examination of clustering is of the overhead. Time spent clustering before layout must not outweigh the performance benefit; it is an instance of the planning problem. \n", "spans": [[0, 55], [56, 179]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "For the case of data visualization, we convert the data structure into arrays with an offline preprocessor. Thus, our data visualizations experience no clustering cost.\n", "spans": [[0, 107], [108, 169]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "For webpage layout, clustering is performed on the client when the webpage is received. We measured performing sequential two-pass clustering. Figure~\\ref{fig:cssrelayout} shows the overhead relative to one pass using the bars. The highest relative overhead was for the Flickr homepage, where it reaches almost half the time of one pass. However, layout occurs in multiple passes. For a 5-pass layout engine where we model each pass as similar to the one we optimized, the overhead is amortized. The small gap between the solid and dashed lines in Figure~\\ref{fig:cssrelayout} show there is little difference when we include the preprocessing overhead in the speedup calculation.\n", "spans": [[0, 87], [88, 142], [143, 227], [228, 337], [338, 380], [381, 495], [496, 680]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\section{Related Work}\n", "spans": [[0, 23]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      representation The representation might be further compacted. For example, the last two arrays will have null values for Circle nodes. Even in the case of full utilization, space can be traded for time for even more aggressive compression [[CITE rinard]]\n", "spans": [[0, 67], [68, 140], [141, 261]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      sims limit studies\n", "spans": [[0, 25]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      duane\n", "spans": [[0, 12]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      trishul\n", "spans": [[0, 14]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "      gnu irregular array stuff\n", "spans": [[0, 32]], "file": "../../thesis/template/chap6.tex"}
,
{"errors": [], "paragraph": "\\section{Sunburst}\n", "spans": [[0, 19]], "file": "../../thesis/template/appendixGrammars.tex"}
,
{"errors": [], "paragraph": "The following attribute grammar demonstrates an animated radial layout. Subtrees expand and contract.\n", "spans": [[0, 71], [72, 102]], "file": "../../thesis/template/appendixGrammars.tex"}
,
{"errors": [], "paragraph": "\\section{Table Layout}\n", "spans": [[0, 23]], "file": "../../thesis/template/appendixGrammars.tex"}
,
{"errors": [], "paragraph": "The following attribute grammar demonstrates the automatic table layout algorithm in HTML and CSS. \n", "spans": [[0, 100]], "file": "../../thesis/template/appendixGrammars.tex"}
,
{"errors": [], "paragraph": "\\section{Multiple Time Series}\n", "spans": [[0, 31]], "file": "../../thesis/template/appendixGrammars.tex"}
,
{"errors": [], "paragraph": "The following attribute grammar demonstrates 3D layout of multiple time series data. Interactive controls enable examining different subintervals.\n", "spans": [[0, 84], [85, 147]], "file": "../../thesis/template/appendixGrammars.tex"}
,
{"errors": [], "paragraph": "\\section{Tree Map}\n", "spans": [[0, 19]], "file": "../../thesis/template/appendixGrammars.tex"}
,
{"errors": [], "paragraph": "The following attribute grammar demonstrates an interactive treemap. Interactive controls enable toggling which value to use for each node and filtering which nodes to show by performing value comparisons.\n", "spans": [[0, 68], [69, 206]], "file": "../../thesis/template/appendixGrammars.tex"}
,
{"errors": [], "paragraph": "\\section{Box Model}\n", "spans": [[0, 20]], "file": "../../thesis/template/appendixGrammars.tex"}
,
{"errors": [], "paragraph": "The following attribute grammar demonstrates specifying a subset of the CSS box model. It is sufficient to render static content from Wikipedia and Wordpress blog.\n", "spans": [[0, 86], [87, 164]], "file": "../../thesis/template/appendixGrammars.tex"}
]
